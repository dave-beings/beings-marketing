# <a id="_heading=h.eofzdx2u67a6"></a>__AI Was Supposed to Cut Research Costs – But Has It?__

*AI was supposed to save us a fortune\. It hasn’t…yet\. But maybe that’s not the point\.*

AI was meant to ease the pressure\. Transcription, coding, synthesis\. all made faster and cheaper by automation\. Projects would move quicker\. Budgets would stretch further\. That was __the promise\.__

## <a id="_heading=h.i2ro5pd8ahz9"></a>As someone building AI tools for this industry, I’ve seen what’s possible\. But does it actually reduce costs across a project or an agency? That’s a different question\.

\_\_\_\_

## <a id="_heading=h.f6y6k4dr7nz9"></a>__What Do You Need to Know__

__The problem?  
__ AI was supposed to cut costs\. It’s saving time in specific places, like transcription and early\-stage coding, but it hasn’t made research cheaper overall\. Instead, the money’s moving around, and expectations are rising\.

__Why it matters?  
__ Budgets are holding steady, but workloads aren’t\. Faster insight means more demand\. Agencies that don’t adapt risk being overwhelmed, while those who embed AI well are scaling output without scaling teams\.

__Where it breaks?  
__

-  AI saves time, but only when it replaces effort
-  Quality still needs human oversight
-  Savings often get reinvested into more work
-  Leadership expects more for less
-  Shallow research creeps in if you’re not careful

__What could help?__

-  Use AI to clear space, not just move the work
- Audit where it’s helping… and where it’s not
- Invest in systems, not shortcuts
- Know where human thinking still adds the most value
- Focus on sustainable efficiency, not just speed

__Want the detail? Keep reading\.__

—\-

Recent findings suggest that while AI does save time on specific tasks, overall spending hasn’t dropped in the way many expected\. A [piece by MX8 Labs](https://mx8labs.com/2025/04/10/know-it-cheaper-how-ai-is-driving-down-the-cost-of-insight-and-changing-who-gets-to-ask-the-questions) highlights this clearly: the cost of a single study might fall, but those savings often get reinvested into running more projects\. In practice, insight becomes cheaper to produce, so organisations ask more questions, more often\.

That’s not a bad outcome\. In fact, it might be the real value of AI in research\. But it does mean the original pitch, that AI would drive budgets down, hasn’t quite played out as promised\.

So, has AI cut research costs? Or has it just changed how we use them?

As I mentioned, it’s not as cut\-and\-dry, so let's see where it’s worked, where it hasn’t and where it’s a bit more… complex\. 

## <a id="_heading=h.i8974cyb7y20"></a>__YES…Sort of…__

AI has brought real savings to certain parts of the research process, particularly in qualitative research\. Transcription, verbatim coding, and first\-pass theming are no longer the time drains they used to be\. MX8 Labs reports that using a large language model for coding can deliver *“90% of the value in a fraction of the time and cost”* when compared to manual analysis\.

Across agencies, this kind of automation is becoming standard\. Tools are now used to group open\-ended responses, surface themes, and create first\-draft summaries, which previously would have tied up junior staff for hours\. Instead of cutting corners, this reduces the hours spent on set\-up and lets researchers move into interpretation faster\.

The effect is measurable\. In the same study, MX8 Labs observed that some teams are now delivering five to ten times as many projects each month without expanding their team\. That kind of uplift doesn’t come from squeezing harder, but from systems that change how the work is done\.

For agencies managing tight timelines and high volumes, the savings aren’t just theoretical\. They’re showing up in output, capacity, and internal cost per project\.

## <a id="_heading=h.qwlalq89wvux"></a>__No…Total project costs haven’t dropped as much as expected__

However, in spite of the savings that others have stated, many research agencies are not seeing a dramatic drop in overall spend\. The efficiencies are real, but the wider financial picture is more complicated\.

 As Michaela Mora writes in[ Relevant Insights](https://www.relevantinsights.com/articles/how-ai-can-further-remove-researchers-in-search-of-productivity-and-lower-costs/), there is increasing pressure to cut costs and deliver faster, but if teams “just outsource everything to technology,” it risks degrading the quality of the work and damaging the human connections at the heart of research\. Tools can misread tone, miss nuance, or produce output that still needs to be checked\. All of that still takes time\.

Transcription is a good example\. While cheaper on paper, the quality isn't always consistent\. *“We were disappointed with transcription quality\. This could be cost\-saving, if done well,”* said one researcher in the same report\. If the output still needs checking or reworking, the cost\-saving quickly thins out\.

There’s also the issue of reinvestment\. MX8 Labs observed that *“lowering the cost of a single study leads to more studies being run\.”* Rather than shrinking budgets, AI tends to stretch them\. The per\-interview cost may drop, but overall spend stays flat as agencies do more with the same amount\.

In most cases, the savings haven’t disappeared, they’ve just moved to different areas of the business and workflow\.

## <a id="_heading=h.4mfeov2ecdup"></a>__What’s actually changing in the numbers?__

Budgets might not be dropping, but the way time and effort are used inside a project definitely is\. This is what that shift can look like when AI is properly embedded into the workflow:

Transcription that used to cost £1 to £2 per audio minute now comes in closer to 10 to 30p\. In many cases, it’s included within existing platforms\. For teams using AI tools like Beings, the cost is rolled into the system rather than outsourced or absorbed through staff time\.

Analysis that once took 10 to 30 hours per project now lands closer to 3 to 6\. AI tools like Beings handle the groundwork, auto\-tagging responses, clustering themes, summarising sessions, so researchers can move straight into interpretation\. The hours aren’t disappearing, but being shifted to where they add the most value\.

Analyst productivity has moved\. Where one or two projects a month used to be the norm, some teams are handling five or more, using the same headcount and toolset\.

That increase in output is changing how work gets delivered\. Topline reports that used to take weeks now arrive in a few days\.

The work still happens\. It just doesn’t feel like it’s dragging the whole team behind it anymore\.

## <a id="_heading=h.mcua2v72bry"></a>__When does AI actually save money?__

The cost savings aren’t automatic\. They depend on how the tools are used, and where they’re deployed in the workflow\. When those choices are made well, the impact can be significant\. When they’re not, the benefit tends to vanish\.

AI tends to deliver the strongest return when there’s volume\. Think things like multiple interviews, long open\-text surveys, or large batches of stimulus feedback\. These are the kinds of tasks that eat up hours and offer little in return beyond the basics\. When AI can step in to transcribe, cluster, tag or summarise at speed, the savings are real and immediate\.

Speed is another factor\. If you’re under pressure to deliver in a week instead of a month, using AI for things like first\-pass synthesis or structuring themes can make the difference between hitting the deadline or missing it\. That speed often reduces the need for extra freelancers or last\-minute hours that push a project over budget\.

But the key condition is this: AI has to replace something\. If it’s layered on top of manual checks or duplicated workflows, the value fades\. When teams treat the tools as draft generators that still need rewriting, it becomes busywork instead of time\-saving\.

It also takes discipline to know which parts of the work still need human interpretation\. Not everything should be automated\. The savings show up when AI handles the repetitive stuff with confidence — and the humans stay focused on what they’re actually good at\.

## <a id="_heading=h.icpo5gvu96bo"></a>__The Jevons Paradox of Research__

In the 19th century, economist William Jevons made an observation that still holds today \- the J[evons Paradox](https://www.techpolicy.press/jevons-paradox-makes-regulating-ai-sustainability-imperative/)\. That means that when technology makes something more efficient, we tend to use __more__ of it, not less\. 

As AI makes qualitative work faster and cheaper to run, demand doesn’t go down\. It increases\. Clients ask more questions\. Teams commission more studies\. Insight becomes continuous, not occasional\. The work expands to fill the new space AI creates\.

That’s what we’re seeing\. Projects that took weeks now take days\.[ __Research has become more accessible to more teams__](https://blogs.lse.ac.uk/impactofsocialsciences/2024/10/30/ai-can-carry-out-qualitative-research-at-unprecedented-scale/), not because budgets grew, but because AI made it easier to say yes\.

That shift has real benefits, but it also comes with pressure\. When speed goes up and cost\-per\-project comes down, senior leadership starts expecting more for less, and not always with a clear view of what’s being traded\. If care isn’t taken, depth gets squeezed\. Nuance gets lost\. Studies that should run deep risk becoming wide and shallow\.

This is the paradox in action\. Efficiency doesn’t shrink the work\. It scales it and if it’s not handled well, it spreads everything thin\.

## <a id="_heading=h.167mzku43dw8"></a>__Where the Value Really Starts__

The biggest savings AI brings to research aren’t always financial and they’re certainly, very rarely instant\! Some show up as extra capacity\. Others come through speed, consistency, or smoother workflows\. The real value is often found in the space it creates: for deeper thinking, faster decision\-making, and more ambitious briefs\.

This isn’t always money in the bank\. Not yet\. But it is movement\. And over time, that movement adds up\.

What’s often overlooked is the cost of standing still\. As research becomes quicker and easier to run, demand is already increasing\. That’s the Jevons Paradox in motion\. More efficiency creates more appetite\. More appetite means more work\. And for teams dragging their heels on adoption, the gap only gets wider\.

Agencies that make the shift early are building capacity before the pressure lands\. They’re choosing to work differently now, rather than being forced to catch up later\.

If you’re trying to make sense of where the real gains are \(not just in cost, but in value\!\) read our companion piece: [__How to Measure the True Value of AI in Research__](https://beings.com/how-to-measure-the-true-value-of-ai-in-research/)\. It’s designed to help you see what’s working, what’s not, and where to look next\.

__What would your team do if you could double your output without doubling your budget?__ 


  
**Speaker 0 (22:15 \- 1:10:35):** To, uh, Gemini or chat GPT. 

**Speaker 1 (1:18:55 \- 1:37:55):** Yay. That's cool. 

**Speaker 0 (1:46:55 \- 14:02:05):** So yeah, these are the kind of things we'll do. Uh, okay. Yeah. Thanks again, Ella. Uh, so I'm \<inaudible\> and my, uh, role in this company beings is the product manager in research and insight, uh, developing. Mostly we are developing mostly AI products for market research and, uh, talking to experts like you. What kind of, uh, different things, uh, could be solved Mm-Hmm. With the, with the help of ai Mm-Hmm. And I will just ask you, uh, a couple of questions along that direction. So can we start with you? Uh, you can explain, uh, please tell me about your job and, uh, what are your day-to-Day responsibilities and what kinda work you do, and then I can start asking more question after that. 

**Speaker 1 (14:17:15 \- 29:16:55):** Yeah. Um, so I feel like my job is, um, so I work with the Insight team, uh, in London, well, um, I'm based in London, uh, but my insight team is, uh, we're like a global, a global team, part of a global company. Mm-Hmm. \<affirmative\>. Um, so, uh, so apco does, uh, sort of communications and public affairs and pr. Um, our team is global, so we're mainly based in the us. Um, and me being based in London as like a team of one, um, uh, I'm part of the Europe team, so there's four of us, and we basically cover Europe and the rest of the world. Um, so it's quite, in terms of kind of my job role role, it's really, um, is really varied. I do a lot of, uh, like I jump between kind more digital, um, digital research. We do quite a lot. 

**Speaker 1 (29:16:55 \- 50:17:25):** Like there's a lot, there's a big appetite of that in London. Um, and that tends to be around sort of like corporate communications, um, and, and thought leadership for companies. Um, and I also do, uh, some, so like opinion research, so conducting, uh, interviews or conducting surveys, um, of various audiences. Uh, and that, that tends to be for either organizations or, um, or it can have like a governmental focus. So, um, in terms of kind of my career, I'm trying to steer it more towards like, working on those sort of governmental projects. Um, doing some sort of like development work, um, working on kind of like developing tourism strategies and, uh, and sort of like economic development, um, Mm-Hmm. \<affirmative\> as well. Um, yeah. And then also sort of in terms of, uh, in terms of kind of my role within London. Um, so I have a, uh, like a responsibility to, um, to communicate offering to, uh, the different verticals within the London team. 

**Speaker 1 (50:27:45 \- 62:58:25):** Um, and try and integrate some sort of insight offering, um, within either the existing client accounts, um, or within, um, business pictures when they're coming along. Um, so we'll often see that there's, that people request maybe like a survey or interviews as part of something. Um, and so then that's when I'll be consulted. Or if we see that they want to, a client wants to, um, conduct a strategy, then maybe we can add, we can persuade them to incorporate an insight element, um, which will be something that may, that informs the strategy. Yeah, I think that question \<laugh\>, 

**Speaker 0 (63:11:25 \- 71:17:05):** No. Yeah. Thank you very much. Yeah, thanks a lot for, for very elaborative answer. Uh, so when you said that you team of one here, uh, so do you have to like decide if, if they want you to do a survey or a qualitative research interview, uh, are you deciding everything by yourself, the content of survey or how whom to target, uh, who should be your participant, uh, how to run the interview? How do you manage all these, uh, technical details when you go for actually conducting the research? 

**Speaker 1 (71:34:55 \- 84:11:45):** Yeah. Um, so I have a, so it's a team of one here, but we're very well connected to, um, so my director is in Paris, um, so I'm very closely connected with her. Um, and also the insight team that's in the us. So typically I would try and answer those questions myself based on, um, kind of the past projects that we've been working on. Um, and that does tend to be like a bit of a rhythm. Um, it tends to, yeah, things don't tend to vary that much. Um, it tends to sort of, yeah, follow some sort of pattern. Um, but then I would always check it with, um, check it by my manager, uh, my, uh, director or, um, another insight colleague in the us. 

**Speaker 0 (84:33:45 \- 86:43:55):** Okay. Brilliant. And, uh, in terms of AI users, uh, have you been using AI at any of these steps of your work? 

**Speaker 1 (86:58:25 \- 105:52:05):** Yeah, I feel like maybe I overly rely on ai. I feel like when think chat GBT went down for a little bit and I was, um, in a bit of a panic, uh, yeah. So I mean, uh, we use it. Um, I, I'd say, so the common times that I would use it are in, so like proposal writing, I find it very useful to, to sort of get \<inaudible\> on the page. So, um, we have, we have a system that we use internally that's a copilot, which, um, is like anonymized. Uh, and yeah, I dunno, there's some sort of connection with our company with, with that, for that to all be sort of okay in terms of the company data. Um, so we're encouraged to use that one. Uh, and I would use that to sort of get words down on a page basically of, um, I would like, I would draft something up, um, in a long-winded way, and then, uh, and then can like ask the AI model to make it a lot more simple. 

**Speaker 1 (106:04:25 \- 124:50:15):** Um, and then I can kind of go in and adjust. Um, and then also in like data analytics, um, we use it for, so we conduct a lot of, um, we use, uh, what's it called? Um, the Open, yeah, open ai, the playground. Um, we use that one for, for interviews. So interview data, um, because it tends to be quite long-winded answers. We do quite a lot of interviews, then we can kind of ask it to pull out the key themes. Um, so we tend to find that our projects are very, um, they're quick turnaround. Mm-Hmm. \<affirmative\>. So, um, it really helps with that is sort of when, um, either once we've done an interview, then you can kind of copy and paste and, uh, yeah. And sort of get the highlights that we can then feed into the team very quickly. Um, or in terms of, yeah, sort of finding overall themes, looking at, um, conversations between interviews and working away. 

**Speaker 1 (124:59:55 \- 143:31:45):** Um, yeah, sort of question by question. Um, then we use that. And then also for the quantitative side of things, then we use, um, we've used like a variety, uh, open AI we use, uh, sometimes, but I think we find that we, that one's better for qualitative. And then, um, Claude is a lot better for, as a platform for, um, uh, analyzing quant data we found. So that will be sort of like copying and pasting a, um, like a data set, uh, like a table a data, table one. Um, and then kind of asking, again, it's like those quick turnarounds when we're asked to provide like a top line finding, um, before we delve in into the, like, the nitty gritty of stuff. Um, then that really, like, that helps us fill out sort of, you know, we've done, we've done a 30, 40 question survey, and then we want to just get like one a four document that has the top line findings, and we'll use that to, um, to sort of very quickly work through the analysis. 

**Speaker 0 (143:56:35 \- 149:01:25):** Right. Yeah, that's very interesting. You're very happy to hear that you are trying to use it as much as possible, whatever is allowed by them. So in terms of, uh, so could you please remind me the name of the tools that you used for different one? You said about OpenAI, but, uh, OpenAI means that you are asking CG, PT to 

**Speaker 1 (149:23:55 \- 155:51:45):** Yeah, I mean, we use the playground one because apparently that's got our, I think we've got some sort of agreement with our company that it's, um, it doesn't, it's in like a closed loop and that it doesn't feed into, um, the, yeah. So we can use like company data basically without it feeding into the, I mean, I hope this is right \<laugh\>. 

**Speaker 0 (156:06:45 \- 161:29:45):** So you mean that, uh, uh, if you're asking Chad GPT, they could use that data for their training purpose, but you have another day, so then you have a data, uh, data privacy or trust, uh, that your data, uh, your private data is not used for training of those AI models. So Yeah. 

**Speaker 1 (161:29:45 \- 162:08:25):** Yeah, yeah. Exactly. Yeah, that's right. Yeah. 

**Speaker 0 (162:23:05 \- 173:50:35):** Okay, great. Thanks. And, uh, when you say that you're copy pasting stuff from one place to another one, uh, so now you're mostly relying on open AI and, uh, it's, uh, you know, supporting tools. Uh, but how are you using AI for any other, uh, aspect? For example, directly a recording of the data, how do you record it? How do you, what kind of tools you use to talk to people? I understand one way is a survey and, uh, what kind of tool you use for this kind of a video recording. Do you use a video recording to talk to people for qualitative research and what kind of tool you use? And, uh, is there any automatic AI involved there to facilitate your interview process? 

**Speaker 1 (174:06:15 \- 190:06:55):** We have, um, so we use like otta ai. Mm-Hmm. \<affirmative\>, um, and we would use, so I'm, I've conducted interviews, um, like this week and we, we've never had it as, um, I think I find because they, the interviews are, um, they're with, uh, they, they tend to be with people. I mean, the projects that I'm on at the moment, they're with, uh, like African government officials. And so we wouldn't have, I think they can be a bit more, um, wary about having someone that's like on the call recording. Okay. So, um, the way that I would do it is to record the interview and then upload it into, um, open, uh, into auto ai, um, which would then sort of create a transcript that's like AI generated Mm-Hmm. \<affirmative\>. Um, and also it has a summary as well, which is useful. Um, yeah. 

**Speaker 0 (190:18:35 \- 191:22:15):** So, uh, have you used your re or any other tool as well? Uh, 

**Speaker 1 (191:35:35 \- 191:46:55):** \<inaudible\>, 

**Speaker 0 (191:59:05 \- 192:04:55):** Sorry, 

**Speaker 1 (192:27:25 \- 192:38:55):** \<inaudible\>, 

**Speaker 0 (192:51:45 \- 193:14:55):** Sorry, I couldn't understand you. 

**Speaker 1 (193:22:45 \- 194:18:55):** What was, uh, what was, uh, what, repeat the question, the tool that you mentioned. 

**Speaker 0 (194:35:15 \- 196:52:15):** Oh, yeah, I was saying that, uh, uh, have you used only yo or is there any other tool in the market that you, you, you have used or you heard about? 

**Speaker 1 (197:23:35 \- 200:30:05):** I think that's the only one for that purpose. I've heard of other ones when they've sort of joined the call. Um, but there's no names that I can think of off the top of my head. Mm-Hmm. 

**Speaker 0 (200:33:35 \- 212:35:45):** Right. Thanks. And, uh, for, for video calls, what kind of platform? You usually use Teams. Okay. And, uh, right, and, and for a, at the end. Okay. So auto can help you, uh, with the, with summaries or key insight. And, uh, do you sometime, uh, still create some kind of a graphical or representation of that data, like, uh, drive, uh, getting pie charts of, uh, sentiment analysis? Do you run sentiment analysis, uh, uh, on, on this research and, uh, do you try to get some kind of, uh, analysis, uh, in the picture or representation, trying to get some figures or? 

**Speaker 1 (212:56:45 \- 228:09:35):** No, we don't. And like, yeah, I mean, that's something that I had never thought of actually, in terms of like the qualitative conversations. Yeah. We, yeah, we really don't, we don't do that. It's all, um, I mean, if we were to assess that, that would be, uh, like we, we, we write up our findings, um, and we, we tend to include and note on that. Um, so we'll write up a finding saying overall, like people were, um, had a positive tone about this, but that's all done. Um, uh, like if I'm the one that writes the research report and say, I know like 10 people had done, um, had done an interview, then I would send a note to, um, like a a, a chat note to all of those people saying, um, uh, could you just like, comment on what you thought the tone was when, uh, respondents asked, answered this question? So it's all very, like, it's after the fact. Um, and it's very like, yeah. 

**Speaker 0 (228:33:15 \- 234:26:25):** Mm-Hmm, \<affirmative\>. Right. Thanks. And, uh, so yeah, you mentioned about survey and this qualitative research interview. Do you also, uh, for, for same product, let's say for one market research project, do you also use quantitative research, uh, to complete your product? Or it's, are, are you mostly qualitative person? 

**Speaker 1 (234:47:45 \- 237:13:45):** No, we definitely, yeah, we use, um, we definitely use both. Yeah. It's, um, I'd say it's probably like 50 50, um, of, of quantum qual. 

**Speaker 0 (237:30:05 \- 239:59:45):** And, and in terms of AI application, uh, where do you think AI could, uh, is helping you more or could help you more qualitative or quantitative research? 

**Speaker 1 (241:04:15 \- 269:58:55):** That's interesting. I mean, I think the, I think the, the thing that you mentioned about sentiment, I hadn't, I hadn't really thought about. And I think that's really interesting. And would I think the, the thing about qualitative research is that we, um, at the moment it takes quite a long time to analyze things and, um, we're, that's, that's sort of understood. Um, and it would be good to be able to like, have a quicker finding, but, um, something like that sentiment analysis I hadn't thought of. And I think that would be useful. The quantitative side is, uh, I think, I think more, um, it would have more reliable results if, um, if we were to involve ai, I feel like I would probably trust those more. I think you can, um, sort of fact check things a bit better. So it'd have some sort of AI component helping out on the quantitative analysis. I think that would make sense more. I feel like the, from having used, um, uh, we use, or like digital analysis, we use talk order, which is, um, is sort of scrapes, uh, scrapes the web for, you know, mentions of whatever, like our client. And then looking at the sentiment analysis that they do there, um, it can be a bit patchy. So I think the, um, I think more there would be a bit of skepticism around, um, having a sentiment analysis, let's say, on qualitative interview data. 

**Speaker 0 (270:19:55 \- 277:55:35):** Oh, okay. Yeah. That's interesting because yeah, that's, that's very different perspective I'm hearing from you now. Like, because many people have very, uh, different, uh, side on that thing. Uh, there's that as long as the year two can understand the context that they will be a bit more cautious about, uh, or they, some of them can trust, some of them cannot trust. So in your line of work, you will have the trust issues about sent sentiment analysis. And would you say that the context would be the bigger reason? 

**Speaker 1 (278:22:15 \- 290:13:15):** I think, I mean, I think, I think trust element is very over easily overcome. Mm-Hmm. \<affirmative\> if when we're sort of testing this, we can see that it works. But I think that, um, I think people are very easy to not trust. And when it comes to, so when we use talk worker, like we use it, um, company wide, and across the company people will say like, oh, you've included, um, the sentiment analysis, but should you really have, like, it's not like you should probably have done your own, your own assessment rather than including the, um, uh, what it's the automatically generated one. Yeah. 

**Speaker 0 (290:30:55 \- 305:17:25):** And, uh, so if you're doing everything by yourself, again, I mean, you are trying to use AI wherever possible, but then again, there, there's certain aspect where there would be trust issue and you would like to do it manually, uh, but then you're going to spend a lot of time there. Uh, but if I, if you have to look at the bigger picture, for example, you have an analysis, you performed your study, and now you're presenting it to different stakeholder. Uh, some of them may not like sentiment analysis. Some of them are interested only in the, you know, summary of the meeting or key actions, uh, just to the point. Uh, but, uh, how often do you think people want to see more than key insight and action items and, uh, items? What is the definition of that more, uh, when they ask you to do something more, what kind of further insight they want to get out of that, uh, survey or, uh, or interview? 

**Speaker 1 (305:43:15 \- 310:32:05):** Yeah, so, so do you mean in terms of, um, so when we do like a, uh, so when we're conducting a research project, um, do you mean in time? What, what more would they want out, um, outta sort of like the final product? Or do you mean as, as sort of like the quick finding? 

**Speaker 0 (311:16:15 \- 322:31:55):** Uh, uh, I think as the result of, uh, final analysis. Okay. Uh, depending on different stakeholder, I think they might want to, uh, get different things. For example, if you're talking to another research manager, you would be happy to talk about, uh, technical details. But if you're talking to your boss or somebody else in the management letter, they might not be interested in technical details. Right. They, they would be probably interested only in one PowerPoint slide that gives you the summary of your whole product that you have worked on for weeks. So my question was that, uh, uh, what kind of different information, uh, you usually drive at the end of the project? 

**Speaker 1 (323:01:25 \- 346:28:45):** Okay. I mean, I think it would be like key themes. That's like a, that's like a massive part of it is, um, there'll be, I mean, it's, it completely depends on the project, but broadly, we're always looking at, um, we'll always be looking at kind of e themes that are important to the client. Um, and then within those themes, what are sort of like the key, um, like what are presented as maybe the key, uh, areas of opportunity or white space. Um, and that will be either something, yeah, that will be something that is, uh, sort of like high in volume in terms of, um, people are talking about it quite a lot. Um, so there's like a lot of interest, but not, there's not, it's not sort of overly saturated. So it's kind of like that sweet spot. Mm-Hmm. \<affirmative\>, um, that's something that we look at and that's where we would feed into, say if we're presenting this to them, to the client, then we would, um, we would be looking on, uh, yeah, we'd be looking at what these, um, what these overarching themes are. Um, and then what within that topic is, uh, is getting a lot of interest. 

**Speaker 0 (365:26:05 \- 365:53:45):** Oh, hi, welcome back. 

**Speaker 1 (366:30:45 \- 367:10:25):** My connection's a bit shit in the office. \<laugh\>, 

**Speaker 0 (367:26:25 \- 368:09:45):** \<laugh\>. No, no worries. Can you hear me well now? 

**Speaker 1 (368:21:35 \- 369:23:45):** Yeah, yeah, yeah, that's, um, yeah, I dunno where it caught me off, but, 

**Speaker 0 (369:54:05 \- 371:15:05):** Uh, just I think, uh, around 20, 30 seconds back when you just started to explain. 

**Speaker 1 (371:38:05 \- 402:26:15):** Okay, great. Um, uh, what was I explaining? Oh, yeah, so, um, we would tend to be looking, when we look sort of in detail, the part that we wouldn't be necessarily walking a client thorough, like the, the, uh, executives through is, uh, are the steps beforehand where we'd be looking at what the overarching themes are. Um, and, uh, and then kind of ranking those. And then the ones that have, um, sort of like the highest volume in terms of, um, as an issue that's being talked about, um, we would then look within that to find key topics. Um, and then we'd be finding topics amongst those that are, um, either kind of like, yeah, basically not overly saturated, um, and would use those as sort of recommendations for thought leadership for the client. Um, but that would require, um, that would require us looking at, um, like us considering what the topics are that a client should be talking about. Um, because say if it's like in the run up to an election, then there's gonna be more policy related topics. And so although that, um, uh, that's the topic of the moment, so the client, we would recommend that they should be referencing some sort of aspect related to that, um, because then they will be, uh, they will be like more visible in the news and the conversation of the time. Um, so that's sort of like the recommendation that we would lead to give to the client, but we wouldn't, um, sort of say about the backend. Did that sort of answer the question or is that 

**Speaker 0 (402:36:05 \- 413:16:55):** Yeah, yeah. Yeah. Very, very well, thank you. And, uh, can, can, can you walk me through, uh, an example of your typical qualitative research project? For example, starting from your product planning, then you are recruiting participant or finding a way to record data, and then your data recording and then analyzing, and then at the end you are doing the interpretation to talk to different stakeholders. So can, can you gimme an example and also tell that, uh, what would be the average time you spent on each of these steps and, uh, also the names of the tool that you are using for different steps? 

**Speaker 1 (413:46:45 \- 431:53:15):** Um, yeah, so from the get go, we would, um, I mean, when it comes to, when it comes to, so interviews, we would, uh, we'd start out by building a list and this is all done, um, either manually, um, we'd be looking on, we'd, yeah, we'd be like manually searching, trying to build together a list of, um, of potential stakeholders to reach out to. Um, or we'd be using talk to, uh, try and to like create a Boolean to find, find people. Um, but definitely not using AI there. Um, and then once we have our stakeholder list, uh, then again, it would all be sort of like manual outreach, um, or we would employ another partner, so another, um, agency to be going up for us. Um, but I think the hard part about, um, compiling the stakeholder list is, um, is finding all the details. 

**Speaker 1 (431:55:35 \- 456:04:05):** So we obviously need like a, we need an email address. Um, and yeah, we don't, we, uh, I mean that's, that's always sort of like the hard part is, um, is finding that, um, compiling all and then, uh, yeah, then the outreach once we've sort of prioritize the list, but everything is like manual up to that point. Um, and then, yeah, outreach is all manual. Um, and then once we, uh, once we have an interview, then, um, yeah, we'd, so we'd, uh, we'd be creating a discussion guide to, um, uh, to work through interview. Um, and that would be like, was like, 

**Speaker 0 (456:46:55 \- 457:09:25):** Hello? Hi, 

**Speaker 1 (457:20:15 \- 458:00:45):** Sorry. Um, yeah, my internet is terrible here. 

**Speaker 0 (458:16:35 \- 461:32:25):** Yeah, it, it was off for about 10, 15 seconds. Uh, but yeah, now I can hear you well. So you were explaining that, uh, yeah, uh, it was, can you hear me? 

**Speaker 1 (461:51:55 \- 463:10:05):** Yeah, I can, I just, um, realized that I have a, um, another meeting, but that's okay. I can push it back. 

**Speaker 0 (463:24:15 \- 464:06:45):** Sorry. Yeah, I will take only like a couple of more minutes then. 

**Speaker 1 (464:39:45 \- 465:22:55):** Um, yeah, so, um, 

**Speaker 0 (465:50:35 \- 466:21:25):** Yeah, uh, sorry, please go ahead. 

**Speaker 1 (466:50:25 \- 484:51:35):** The, um, so from this stage of, yeah, all manual up until we get to creating the discussion guide, um, creating the discussion guide we use, uh, at GBT to kind of more for like idea generation, um, thinking of sort of like alternative ways to ask a question. Um, and, but I feel like there's potentially something, there's some sort of way to make that process a lot easier. Um, I haven't seen any tools that are out there that would help with discussion guides. I've seen them for surveys, um, but I haven't got around to testing any. Um, but the discussion guide point, it's there, like our discussion guides always quite similar, so we tend to, the best way to do it tends to be to, to think of a project that we've done that's similar and then go through a similar discussion guide and like pull maybe three or four together and then sort of look through, um, questions, um, to try, yeah, to sort of ideate. 

**Speaker 1 (484:51:55 \- 504:06:15):** And then we'll tend to formulate that on our own or use the help of like tattoo bt to, you know, improve the language or make this less direct or something. Um, and then in terms of the interview, um, we book this in or manually, um, or our partner would do it. And then, yeah, the transcription is then the, the next time. But we'd, um, involve ai. Um, and I mean, I personally don't tend to look at the summaries. Um, I find that there, I I find that they're quite long-winded, and I would prefer to, um, I would prefer to sort of look through things myself, um, because they, yeah, the summaries on Otter AI are, I mean, they're, they're big. They're sort of like, it's like a, it's sort of a, it's probably like a, a couple of eight sides of four or something. Um, so I would rather speak to the person that's conducted the interview and, um, and get them to tell me their key findings or there's anything interesting. 

**Speaker 1 (504:13:55 \- 516:01:45):** Um, and then they can direct me or they'll, they'll be writing up notes themselves, um, during the interview, and then we'd put these basically into a matrix. Um, and yeah, so this would all be in a matrix. You'd have like interview long hair and questions going down and columns. And then when it comes to the reporting, I'll look downwards and look as like, um, the key along interview questions for, um, full of common themes. And then I'd probably enter that into a, um, like an AI system to try and, uh, generate key themes. Um, but then I'd also look myself to double check if there's anything that's missed. 

**Speaker 0 (518:37:05 \- 518:42:55):** Hello? 

**Speaker 1 (519:30:15 \- 519:36:05):** Hello. 

**Speaker 0 (519:46:35 \- 521:53:15):** Yeah. Can, can you hear me well now? Can you hear me? 

**Speaker 1 (522:08:15 \- 524:27:15):** But, um, yeah, yeah, that's perfect. One moment. 

**Speaker 0 (525:18:55 \- 525:48:05):** Sorry, I cannot, uh, I can 

**Speaker 1 (525:48:05 \- 525:52:45):** Hear you. 

**Speaker 0 (526:33:05 \- 528:17:55):** Okay. I will also switch off my video then for a minute. Uh, how, how about now? Can, can you say something? Okay. 

**Speaker 1 (528:43:25 \- 529:22:35):** Can you Yeah, go. 

**Speaker 0 (530:05:35 \- 571:48:34):** Uh, yeah, sorry, I, I don't really understand. You still, do you want to like, uh, uh, leave the meeting and come back again? Okay. Hello? Hello. Hi. Uh, yeah, now it's much better. 

**Speaker 1 (572:07:45 \- 572:37:55):** Okay. That's good. Yeah, I think these, 

**Speaker 0 (572:47:05 \- 572:55:54):** Yeah, thank 

**Speaker 1 (572:55:54 \- 573:16:35):** You. The wifi is terrible. 

**Speaker 0 (573:38:55 \- 574:49:15):** No worries. Or do, do you have to run now or do you you have like four or five minutes? I just have like, 

**Speaker 1 (574:50:25 \- 575:30:35):** Yeah, yeah, that's, yeah. Yeah, that's fine. 

**Speaker 0 (575:50:25 \- 582:33:45):** Okay, great. Yeah. Uh, thank you very much. Uh, so you were mentioning something about the problems with ot, so I just want to clarify that. Uh, did you mean that, uh, uh, the information, like these summary or insight that auditor is giving you are not enough and you still feel like there is no way to get it more, and you will prefer to talk to the person who interviewed actually instead of taking it as it is? 

**Speaker 1 (582:52:15 \- 599:53:25):** Yeah, I think it's the fact that, um, when we do, uh, when we do these interviews, we want to, we are running through, like the way that we analyze it is on theme. So we have, say, three themes per interview or more whatever. So you have three. And then within that, within those themes, we'll have, uh, we'll have like three to five questions. Um, so I, reading summary doesn't necessarily help because it's looking at too much of an overview. How I need is to look at those, I need to look at themes individually. Um, and then talking to the person is really useful because they can maybe, maybe an interview hasn't followed the appropriate, um, flow of the discussion guide. Maybe they've, they've had to sort of like go with the flow a bit more, and they've had to, they've had to deviate from that. 

**Speaker 1 (600:02:25 \- 617:37:15):** Um, so then they're able to, um, to pick up on things, um, which yeah, which I, maybe it's something that the interview emphasized at the start and then maybe they emphasized at the end. Um, but it's, yeah, it's, it's like part of a different section. Um, and there was one other thing that was something \<inaudible\>. Um, oh yeah. So the other, the other good thing is, um, when I would use it is because you can, um, you can search for a word. Um, so when I go to, uh, analyzing across interviews, we'll upload all of them into one folder and then type something like, like a client's name, and then you can find quotes really easily, because that's like another part of reporting is, uh, is, is picking out sort of these key points that, um, that we can then, um, send over to a client that maybe portrays the point that we're trying to, um, we're trying to portray in like a better way. 

**Speaker 0 (617:48:55 \- 619:43:15):** Mm-Hmm, \<affirmative\>. Right. Yeah. Thank you. And the, the last line that you mentioned, uh, uh, is it the future that you have in order, 

**Speaker 1 (620:57:55 \- 621:14:55):** Is it a feature? 

**Speaker 0 (621:31:55 \- 627:35:35):** No. Like, like you said that, uh, there are like a lot of interviews in the, in the same folder, and you can drive, you can get like key insight, uh, from, but just the type name of the, and you can get like different insight from all of these. The answer could have been better. Did you explain it that this is something in OT or this is your wishlist? 

**Speaker 1 (627:57:55 \- 651:47:45):** No, that, yeah, so that's something in Otter. Um, I mean, the way that they do it is that you type in, say you type in the client's name. Yeah. Um, then it will literally just give you the place in the interview that the client was mentioned. Yeah. Um, and then you can go through, say if we do like 40 interviews Mm-Hmm, \<affirmative\>, um, then straight off the bat, you can find straight off the bat. That means that you can, you can basically count to see how many times that, um, that they say the client mentioned. Um, say, one of our questions would be something like, um, word, uh, our questions would be like unprompted, uh, does the clients, does the client come to mind? And so we would, we would search the name of the client, and what I, what otta does do is it, um, brings every time that it was mentioned, or what it would be better if it could do was, um, if you could somehow plug in where our question is, because that is like, and then to be able to find, easily look at like the quantitative data of, we've done 40 interviews, 10 of them knew question one, they mentioned, uh, Pfizer straight away. 

**Speaker 1 (651:54:05 \- 654:03:05):** So that's like whatever per whatever percentage that is. Um, that's something that Okta doesn't do, but it would be really useful. 

**Speaker 0 (654:12:05 \- 656:39:05):** Mm-Hmm. \<affirmative\>. Right. Thank you very much. Uh, I, I just like, good. Now, so what is the average cost of your one, uh, qualitative project usually? 

**Speaker 1 (657:07:25 \- 658:05:05):** Uh, uh, wait, sorry. The, out of, um, the qualitative project? 

**Speaker 0 (658:21:35 \- 659:45:05):** Yeah. What is the average cost in terms of time and, and money? Uh, is it something that you can tell? 

**Speaker 1 (660:11:55 \- 678:30:35):** Um, I mean, I would probably, hmm. The average is quite, like, they range a lot, I would say. So we tend to charge, uh, we, we charge probably 25 to 25 would be, um, like a very small sample. Um, uh, and our benefit that we're always driving is, um, like as an advisory. So we like our, that whole element of, of advice and key recommendations is like a strong part of that. So, uh, in terms of kind of looking at a small sample of pizza, um, that would be like a low amount of our time doing actual interviewing. The main part is that we'd be charging because of our time of like developing the advice and doing the analysis. Um, so we between like 20 to would probably cost, um, around like 70 to upward of that. 

**Speaker 0 (678:46:45 \- 694:04:35):** Okay. Yeah. Very good. Interesting. Thanks a lot for that. Well, this last question about your wishlist now, uh, uh, and if you have to tell me that, uh, if there is no problem from technology point of view or funding point of view, what would be your wishlist as a researcher from, uh, from AI that, uh, what are the different things that it can solve for you? How can it, uh, not research, but also management, like you have mentioned from one place to another place, and then you're sharing, you also, uh, spend time on moving from one project to another for search and project management. How can ai, uh, what are your wishlist from ai? You can say anything. Um, 

**Speaker 1 (694:22:25 \- 719:36:45):** Yeah, I feel like that's really hard because I think there's, there's a lot. Um, I feel like, I mean, in terms of, yeah, I feel like there's a lot, there's, um, there's just so much kind of, uh, like copying and pasting and, um, what did I say as my wishlist? I feel like, I feel like a lot, like a lot of our, um, our problems come from, uh, as being part of like a research team as part of, and like wider, uh, a wider like communication company. So we do a lot of like crisis communications, um, and like a lot of like issues and, uh, yeah, sort of issue management. And that all requires a lot of like fast, fast-paced reporting. Basically, the whole company, apart from our team are a lot more used to, um, and they, and they want, um, this sort of like fast-paced, um, report delivery that I feel like sometimes holds our team back, um, in terms of people who don't want to work with us because they think that we're always like in the weeds and we're always taking a bit too much time with either the data analysis or the setting up of a project, and they want us to sort of like, immediately when an issue advisors, they would like us to do like a cook and dirty interview thing or, or something. 

**Speaker 1 (719:43:05 \- 745:30:25):** Um, and I think that's what, like, a lot of the, we're held back a lot by, um, uh, by our own processes. Um, so I feel like there's, like, there's a lot of ways that AI could help us out, which is why, um, I'm relying on it a lot for kind of, uh, for doing a lot of the, um, either like report creation in terms of just getting like, text on a page or the same with like, new business because I need my time to be focusing on the thoughtfulness with the strategy, um, rather than on more like, mundane things. Um, so yeah, I feel like anything that can kind of help with help withing like a more streamlined, um, analysis or with like project set up, uh, in terms of like creating discussion guides, creating, um, creating questionnaires, at least, just like basically just getting something on the page that then we can react to. I think that's like the main, the main thing is, yeah. And also in terms of like, yeah, that's, 

**Speaker 0 (746:40:45 \- 747:36:55):** Yeah. Thank you very much. That was very elaborate.
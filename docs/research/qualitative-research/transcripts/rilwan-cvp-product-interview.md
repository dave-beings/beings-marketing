# Interview Transcript: Rilwan, C/VP Product & AI Engineer

*Converted from: Rilwan, C_VP Product.docx*  
*Original size: ~500KB, Conversion date: September 10, 2025*

## Participant Profile
- **Name**: Rilwan
- **Primary Role**: Product Manager/Developer (formerly at Experian)
- **Secondary Role**: AI Engineer (10+ years experience)
- **Research Experience**: User research as additional responsibility (6 years)
- **Current Project**: Owner of user research platform (side business)
- **Unique Perspective**: Triple expertise in development, product management, and AI

## Interview Context
- **Interviewer**: Anna Sandford-James (Scale Up Collective)
- **Purpose**: Understanding researcher needs for AI research tool development (Beings platform)
- **Format**: Remote video interview
- **Focus**: Multi-role research experience and AI integration insights

## Background & Career Journey

### Unconventional Research Path
- **Not traditional researcher**: Came to research through product management needs
- **Triple role at Experian**: Developer + Product Manager + User Researcher
- **Internal product focus**: Conducted research for internal tools and users
- **Time constraints**: Research conducted outside regular hours due to competing priorities
- **Access advantage**: Internal users provided regular access for research

### Current Business
- **User research platform**: Comprehensive remote research tool
- **Non-AI focus**: Covers all types of remote user research methods
- **Built-in capabilities**: Video chat, transcription, analysis tools
- **Personal use paradox**: Builds tools but often doesn't use own AI features

## Research Methodology & Approach

### Research Classification System

#### Macro Research (Strategic)
- **Frequency**: Every 6 months or when market changes occur
- **Purpose**: Long-term strategic initiatives and overarching reviews
- **Scope**: Broad, organizational-level insights
- **Time investment**: Significant but infrequent

#### Micro Research (Tactical)
- **Frequency**: Weekly or bi-weekly
- **Purpose**: Address immediate problems and quick fixes
- **Scope**: Specific issues and rapid iterations
- **Primary focus**: Most regular research activity
- **Connection**: Links to product discovery processes

### Interview Methodology

#### Question Strategy Challenges
- **Primary challenge**: Asking the right questions and appropriate follow-ups
- **Bias concern**: Avoiding leading participants in desired directions
- **Preparation vs. execution**: Planned questions vs. spontaneous follow-ups

#### Note-Taking Approach
- **Retrospective method**: Notes taken after sessions, not during
- **Story-based memory**: Remembers narratives rather than specific quotes
- **Recording reliance**: Uses recordings for detailed review
- **Comparison method**: Cross-interview analysis through post-session notes

#### Reasoning for Retrospective Notes
- **Attention preservation**: Avoids missing key details during conversation
- **Engagement priority**: Maintains focus on listening rather than documenting
- **Interview quality**: Prevents sessions from becoming scripted question lists

## Technology Use & AI Perspective

### Current Tool Usage
- **Recording**: Standard video conferencing tools (Zoom, Google Meet)
- **Transcription**: Limited use, prefers manual review
- **Analysis**: Custom-built platform with manual tagging preference
- **Integration**: Avoids daisy-chaining multiple tools

### AI Engineering Insights

#### AI Bias Understanding
- **Fundamental limitation**: AI always has one perspective, cannot be trained on contradictory views
- **Training data impact**: Reflects biases present in training datasets
- **Geographic bias**: AI trained in one region may be biased against others
- **Cultural implications**: Political and cultural views embedded in AI responses

#### Bias Mitigation Strategies
- **Human-AI collaboration**: Use opposing subjective views to achieve objectivity
- **Manual oversight**: AI critiques human work, humans critique AI work
- **Conscious bias awareness**: Understanding that complete objectivity is impossible

### Platform Development Experience

#### Custom Research Platform Features
- **Integrated video chat**: Built-in communication system
- **Automatic transcription**: Available but personally unused
- **Thematic analysis**: Manual tagging and highlighting system
- **Visualization tools**: Filter and analyze qualitative data like quantitative
- **Prototyping integration**: Figma integration with HTML conversion for usability testing

#### Tool Integration Challenges
- **Complexity aversion**: Prefers single-platform solutions over tool chains
- **Efficiency focus**: Seeks fastest path to insights
- **Custom solutions**: Built own tools to address specific workflow needs

## Research Process Challenges

### Primary Challenges
1. **Time constraints**: Balancing research with development and product responsibilities
2. **Question formulation**: Asking unbiased, appropriate follow-up questions
3. **User availability**: Working around internal user priorities and schedules
4. **Tool limitations**: Standard tools not specialized for research needs

### Platform-Specific Issues

#### Video Conferencing Limitations
- **User interviews**: Generally adequate for verbal communication
- **Complex research**: Inadequate for usability testing, ethnographic studies
- **Specialization gap**: Not designed for research-specific needs
- **Recording challenges**: Manual upload and processing required

#### Usability Testing Challenges
- **Video review burden**: Must manually review recordings for validation
- **Comparison difficulties**: Hard to compare across multiple sessions
- **Efficiency needs**: Requires fast, efficient analysis methods
- **Moderated vs. unmoderated**: Different tools needed for different approaches

## AI Integration Philosophy

### Personal AI Usage Paradox
- **Available but unused**: Has AI features in own platform but prefers manual work
- **Bias consciousness**: Understands AI limitations from engineering perspective
- **Quality concerns**: Prefers human judgment for critical analysis tasks
- **Efficiency vs. accuracy**: Chooses accuracy over speed for important insights

### AI Implementation Insights
- **Training challenges**: Cannot train AI on contradictory perspectives
- **Contextual limitations**: AI lacks understanding of specific business contexts
- **Bias inevitability**: All AI systems inherit biases from training data
- **Human oversight necessity**: AI requires human review and critique

## Strategic Implications for Beings

### Unique User Profile
- **Multi-disciplinary expertise**: Rare combination of research, product, and AI skills
- **Quality-focused**: Prioritizes accuracy over efficiency
- **Tool builder**: Creates solutions for identified gaps
- **Bias-aware**: Deep understanding of AI limitations and risks

### Key Requirements
1. **Bias transparency**: Clear understanding of AI decision-making processes
2. **Human-AI collaboration**: Tools that enhance rather than replace human judgment
3. **Workflow integration**: Single platform solutions over tool chains
4. **Specialization**: Research-specific features beyond general communication tools

### Market Insights
- **Tool fragmentation**: Current market requires multiple tools for complete workflow
- **Specialization gap**: General tools inadequate for research-specific needs
- **Quality vs. speed**: Researchers willing to sacrifice speed for accuracy
- **Custom solutions**: Users building own tools to address market gaps

## Key Quotes

### On AI Bias
*"AI is biased as well to some degree... it's always gonna be biased in their political views and their cultural views... that could have a negative impact on the outcome of the research."*

### On Research Approach
*"I didn't want an interview to be the case whereby I'm just running through a set of questions and not even listening to their answers."*

### On Tool Integration
*"Having to daisy chain different tools together to get it to do this, this, and this... just became a headache. So I just look for other approaches."*

### On AI Training Limitations
*"You can't train it on opposite views... you can only train it in one direction... so let's say if it's trained in America, all of the countries that are not allies will have data that makes those people look negative."*

### On Manual vs. AI Analysis
*"I prefer to do the thematic analysis manually using my own tool... because AI is biased to some degree, you can try and make it as unbiased as possible, but generally it means one subjective view."*

---

*This interview provides unique insights from a researcher who is also an AI engineer and platform builder. The participant offers deep technical understanding of AI limitations while maintaining practical research experience, representing sophisticated users who understand both the potential and pitfalls of AI-assisted research.*

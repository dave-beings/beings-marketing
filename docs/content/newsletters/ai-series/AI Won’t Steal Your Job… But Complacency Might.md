<a id="_ivf7jk5dcopo"></a>AI Won’t Steal Your Job… But Complacency Might

__*Stay sharp, think better, and avoid becoming replaceable*__

This is a cautionary tale, one that you may not even realise is happening until it’s too late\. And while typically my content is directly related to research and the researcher, this one is relevant to everybody within any business\.

Here’s what I keep seeing: some people are learning to work with AI… properly\. 

They’re figuring out what it’s actually good at\. They are realising what its limitations are, and with a varying degree of inclusion, they are putting in the right amount of thought and effort that allows AI to enhance what they do\.

But others are coasting\. The ones that press the buttons, paste the output, give it a cursory glance, and think “that will do”

## <a id="_9aup4w3e9bv4"></a>Don’t run the risk of switching off your brain and thinking no one will notice\.

### <a id="_gpdjvacyld5x"></a>__What Do You Need to Know__

- __The problem__: For some people AI is being treated as a shortcut instead of a skill\.  

- __Why it matters__: When firms skip the learning curve, they end up with faster bad work, not better work\.  

- __Where it breaks__: Passive prompting gives you exactly what you asked for\. Not what you *meant*\.  

- __What could help__: Reframing AI as a research assistant with range, but not a substitute for attention, iteration, or expertise\.  


I __*do*__ get it\. 

Everyone’s stretched and nobody wants another thing to master\. But if you're working in research and you're not curious about how to actually use this technology, not just prompt it, but shape it, challenge it, then yes, it might replace parts of your job… or even you\. 

This is not because AI is that clever, nor is gunning for your role, or is part of a conspiracy to “save money”\. It is simply because, for many, they will have stopped paying attention and have dropped the ball\.

Right now, you’ll find that a lot of teams are playing with powerful tools and putting out really average work\.

It looks decent on the surface, because AI is very good at the polish\. Everything looks sharp from the deck, including the figures and layouts\. All the right phrases in the right places, but there’s nothing of true value underneath\. You have a shiny load of data that doesn’t actually say or do anything of value\.

And once you know what to look for, it’s actually very easy to spot\.

The questions stay on the surface\. The quotes don't land\. The recommendations could have come from anywhere\. The analysis doesn’t move anything forward\. It ticks all the boxes, but no one feels any clearer; they are just quietly deflated\.

The work is getting done… but it’s not getting any better\.

And that’s the risk\. AI *can* help us produce better work faster, but only if we treat it as part of a thinking process, not a replacement for thinking and doing as a whole\.

### <a id="_gz5wa3f8c3o"></a>__Most People Aren’t Using AI, They’re Using Templates__

Paste in a transcript\.  
Ask for themes\.  
Copy\-paste them into the deck\.  
Job done\. 

This is what’s happening in far too many firms\. It looks efficient and fast, but the *work* is shallow\. No sense\-checking\. No rigour\. No tension\. No synthesis\. Nothing of the quality that’ll give it its value\. 

Really importantly, this isn’t a critique of AI\. It’s a critique of how __humans are choosing to engage with it__\.

### <a id="_ornahmwbmwpl"></a>__Lazy Prompts Create Lazy Outputs__

This isn’t an active choice, people aren’t just going “Oh well\! I can’t be bothered, I’ll get the AI to do and have a long lunch\.” It’s that most people don’t know how to *ask for it* properly\. Prompt engineering, like asking questions in a research interviews is both an art and a learned skill\. 

A [2025 study from the Universität Hamburg](https://www.mdpi.com/2673-2688/6/2/35) directly supports this\. Researchers compared prompts of different quality and found that *only* the highest\-quality prompt produced consistently strong feedback\. The mid\-level prompt,  the one that looked polished but lacked depth, actually introduced *more* errors than the worst one\. The authors called it a “wolf in sheep’s clothing\.” Smooth on the surface\. Useless underneath\.

They also found that when well\-prompted, ChatGPT\-4 outperformed expert educators in categories like explanation, specificity, and question\-asking\. Simply because it was given a better brief\.

So if your input is vague or undercooked, the output will be too, no matter how confident it sounds\. 

And this is what we are finding across the board is that people will be using AI, but they give the model too little context or they rely on generic, passive commands:  
“Analyse this\.”  
“Summarise that\.”  
“Write it in a friendly tone\.”

The question then becomes less about what the model can *say* and more about how to help it say something worthwhile\.

And the answer starts with what you give it\.

### <a id="_n417zkwuzfkj"></a>__It’s Competitive Erosion\.__

As mentioned in the title of this AI probably won’t take your job, but someone who uses it better might\.

See, access to tools in research is no longer the USP for an individual or a firm\. Everyone has them now to varying degrees\. The gap now is how __well__ you can work with AI, stress\-test its outputs, and still think critically\.

If you’re not doing that, you’re slipping and it will be hard to catch up\. Because as others get sharper, faster, and more confident with these tools, any edge you had or expertise you have cultivated will start to fade\.

That’s competitive erosion\. Not a dramatic collapse, just the slow drift of relevance\.

And it doesn’t just apply to individuals\. It affects teams, agencies and even entire firms\.

If the work stays shallow while others are digging deeper, clients will notice and they’ll start to look elsewhere\.

It might sound like a cliché, but you really do need to treat AI in research like an intern\. A smart, eager junior who’s there to help but only knows what you tell them\. If you don’t give it proper direction, it won’t produce anything useful\.

That means taking time to understand what makes a good prompt, where you actually want to speed things up, and where your own judgement still matters\. It also means knowing when to step in, ask better questions, and shape the output\.

Treat it like part of the team, not just a shortcut, and the results will speak for themselves\.

### <a id="_mx66xtsgd0pd"></a>__Keep Driving\. But Drive Better\.__

I was thinking about how this looks in a super simple context and I kept thinking back to elite Formula 1 drivers like Verstappen, Hamilton and Norris\.   
  
You can give everyone an F1 car, but only a few will learn how to brake early, take corners right, and trust the grip\. They’ll look at the data, they’ll take micro actions to improve those little discrepancies and become better\.

Give that same car to anybody who has points on their license and they will likely spin out\. They may get a few lucky turns but they won’t match speed or handling because they never took the time to understand what it was built to do, or spent the time learning how to do it\. 

The same is true for AI\.

It’s not going to replace researchers\. But it *will* replace firms who treat research like formatting\. Who treat AI like an intern they barely manage\.

The edge now? It’s in who’s willing to *learn* what they make possible, and how to drive them, fast and well, under pressure\.

So:

__Are you using AI to *think*, or to tick boxes?__

Because if it’s the latter, don’t be surprised when your clients stop noticing what you deliver, and don’t be surprised if they start heading off to find people that get it\. 

If you’ve read this far, you’re probably already thinking about how to avoid all this\. Check out our companion guide: The Researcher’s Competitive Advantage in the Age of AI\. This will give you some insight, ideas and practical tips on how you can ensure that your output is good, and when to sense check yourself\. If you’re not sure, then get in touch with me and we can talk about how the right AI, the right attitude and correct approach makes all the difference\. 


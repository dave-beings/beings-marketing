# Jon Priest - Warm-up Chat

*Converted from: Jon Priest - Warm-up chat (1).docx*  
*Original size: 25K, Conversion date: September 10, 2025*

 Speaker 0 (00:02 - 00:08): And it's temperature. It's the first game of the season. Temperature's gonna drop <laugh>. So I've been looking for a jump pass. 
 Speaker 1 (00:09 - 00:09): Oh no. 
 Speaker 0 (00:10 - 00:12): <laugh>. Uh, 
 Speaker 1 (00:12 - 00:13): Where do you play? Do you play locally somewhere? 
 Speaker 0 (00:13 - 00:23): I play locally in Essex. Yeah. Um, I still labor under the misapprehension that I've got something to offer the team, um, other than making teas <laugh>. 
 Speaker 1 (00:23 - 00:26): Nice, nice. As long as you enjoy it. As long as you enjoy it. 
 Speaker 0 (00:26 - 00:47): Yeah. Yeah. I think you one those thing. You can keep going really. Until, until, until you are, until the, um, uh, osteoarthritis gets too bad. <laugh>. You are. But anyway, it's nice to see you again. Um, tea, I must ask you, you were, you were looking when we first spoke, I thought about having a start date for April, um, for beings. Are you, are you live now? 
 Speaker 1 (00:48 - 00:53): Uh, we are. Uh, am I happy with where we are live? No, not so much 
 Speaker 0 (00:53 - 00:53): <laugh>. 
 Speaker 1 (00:54 - 01:18): My, uh, I'm, I'm absolutely following the lean startup model. I'm just saying, well, look, as long as, um, as long as there is something that you can do with it, then I will share it with people, and then the sooner I share it, the sooner I'm gonna get feedback and, um, we'll just improve it, improve as we go. 'cause I have been known to be a perfectionist historically, and in software that will just Yeah. That will kill us if I, um, keep waiting until it's ready, you know? 
 Speaker 0 (01:18 - 01:30): Yeah. Well, I guess a soft launch and then iterate it as feedback comes in. It's a good play. Yeah, exactly. Well, excellent. Well, I've done some prep on the kind of discussion points that you wanted to cover, so, yeah. Is there anything 
 Speaker 1 (01:30 - 01:41): Else that, um, you know, that's quite a generic set of questions, but I wanted to leave it quite open-ended, and then kind of see, yeah, see if there's anything in particular that, um, that you felt, um, you wanted to offer. 
 Speaker 0 (01:42 - 02:02): Well, we'll see how we go. I think we can use your structure was very good. And I think then maybe when it comes to the live recording in a week, two weeks time or so, then we'll be able to hone down on the things that are particularly cogent, I guess, and edit out all the stuff that's not really helpful. But yeah, I'm more than happy to help. Do you have your advisory council in pretty much in play now, do you think? 
 Speaker 1 (02:02 - 02:25): Pretty much, yeah. Thank you so much. I do appreciate all of those, um, introductions. Um, yeah. Everyone seems great. And I'm similarly, I was just like, well, look, let's just try one. I'm gonna set one up for June, I think. Um, and just try and get people together. Mm-Hmm. Um, but yeah, love, loved, loved it. Yeah. Danny was, you know what you've, I think what you've done really well is just totally different people from totally different Yeah. 
 Speaker 0 (02:26 - 02:26): I, i 
 Speaker 1 (02:26 - 02:28): Lines, you see what I mean? Um, I 
 Speaker 0 (02:28 - 03:03): Did, I wanted to propose sort of an eclectic collegiate advisory council or suggest that to you. So Danny is very well versed. Mm-Hmm. <affirmative>, um, and is plugged into the industry. Yeah. Um, Carvin is, is is very, very good actually. Um, particularly for the client perspective. Mm-Hmm. <affirmative> Graham Hall is a genius qualitative researcher, repeat, and he's a lovely man and very interesting man to talk to and then myself who can, you know, um, add whatever value I can. But yeah, we appreciate it. We're keen to help and wish you best luck. 
 Speaker 1 (03:03 - 03:08): Thank you very much. Yeah, it's gonna be, uh, it's gonna be a crazy, a crazy few years, I think, but hey, 
 Speaker 0 (03:08 - 03:08): Well, hey, 
 Speaker 1 (03:09 - 03:09): Happy days. 
 Speaker 0 (03:10 - 03:46): One of the thing you asked, one of the things you asked me about was how I started in the industry. Um, so, um, well, it'll be, um, August Bank holiday coming up will be my 40th year anniversary in, in what was known as market research back in the day. And it's all <inaudible> into insight and data now. Mm-Hmm. I've kind of lived through the changes that probably have culminated to where we are now with ai. Um, but yeah, I joined on as a grad, um, as a research assistant in the inside department of British Gas. 
 Speaker 1 (03:47 - 03:47): Okay. Fabulous. 
 Speaker 0 (03:48 - 04:18): And I didn't quite realize at time there significance. This is around, um, when they were floating to become a private company. And, um, they were a considerable spender of market research and had quite a lot of agencies on roster, which I didn't really appreciate at the time. Mm-Hmm. But it was quite a good grounding. And then, then I've got a combination of client side and agency side, agency owner, Mm-Hmm. And now sort of corporate advisory to the sector. Mm-Hmm. So, covered off both touch points, I think. 
 Speaker 1 (04:19 - 04:35): Yeah. No, I think that's a, a fascinating way to, a fascinating breadth of experience across the industry to sort of see it kind of full, full width in that sense. Um, just going back to actually, like how you literally, how you started, like what did they do? Did they put you in a graduate training scheme or was there like No, 
 Speaker 0 (04:35 - 04:55): They didn't really, it was a strange one. Yeah. Um, I wanted to go, A lot of people talk about, I think I'm a slight anomaly in many, in many ways. People talked about how they got into market research and the default answer afterwards, people didn't really decide to do it. They kind of fell into it and then they enjoyed, I actually was one of the rare people who wanted to work in it Right. 
 Speaker 1 (04:56 - 04:57): To it in the first place. 
 Speaker 0 (04:57 - 05:44): Yeah. It was kind of closest to the subjects I enjoyed most in, in my degree. And at that time I thought, well, why not have a job that is meant to sort of be a facsimile of the things that you enjoyed when you were studying? Mm-hmm. Was my logic at the time because I, I, I wanted to sort of do research and write reports in a very earnest way Mm. To do when you're a grad. Um, but when I joined, they didn't really have a graduate trainee program, so I wasn't on the graduate training program. Um, I was, it's just a job. Mm-Hmm. <affirmative> that had to be someone who has a graduate starting off at the bottom as a research assistant, a a an assistant market research officer as I was called because they was still a public company by then. Um, yeah. 
 Speaker 1 (05:44 - 05:51): Yeah. What were they trying to find out? What sorts of things? Like what, why did they, uh, value it? You said it was quite a large department within the organization, you 
 Speaker 0 (05:52 - 06:44): Yeah. Well, British cast has very big undertaking and, um, obviously they have, you know, millions of customers. Mm-Hmm. So the early, early, um, experiences of, of customer experience research, really satisfaction with Mm-Hmm. <affirmative> with, um, service people who would arrive at the property. That was quite a big theme. Mm-Hmm. Awards every year for the best sort of regional service engineers who would go out Mm-Hmm. <affirmative>. So that, that a chunk of time. Mm-Hmm. <affirmative> and leading up to their, their flotation with the quite infamous issue, <inaudible> tele campaign, which was all over the media at the time Mm-Hmm. In the mid eighties. Lot of corporate image tracking about how, how the organization was perceived as an employer and sort of in terms of corporate strategy, it's sort of governance and oversight reputation, things like that. 
 Speaker 1 (06:44 - 06:45): Yeah. Yeah. 
 Speaker 0 (06:45 - 06:46): You did quite a lot of, 
 Speaker 1 (06:46 - 06:52): You said, if I'm right, hearing you right, you've kind of said customer experience so far. Brand reputation so far. 
 Speaker 0 (06:52 - 07:52): Brand reputation, customer experience, quite a lot of new product development research as well. So things like gas cookers and power showers, and any appliance that could use gas. This is in the time when most high streets had a British gas showroom and people would go in and buy stuff. Wow. Um, and then every two years they used to do a huge establishment survey, um, of about 50,000 homes. Um, this is when interviewing was done in the home face-to-face, um, in a traditional way. Mm-Hmm. There's an audit really of what appliances people had and, and how they cooked their food and how they heated their water. And they used to do that to track, um, changes in product penetrations. This is the time when, for example, microwave ovens was really, they're really still quite new. Mm-Hmm. Track the penetration of those over time. Mm-Hmm. Um, so it was as, as a sort of grounding of the kinds of insight that you can do, either as <inaudible> as a provider or, or client commissioning. It was quite a good grounding, I think. Good fun too. 
 Speaker 1 (07:52 - 07:59): Yeah. Yeah. Was there anything that really surprised you that you discovered, uh, that you just had no idea, some kind of key insight that made a big difference? 
 Speaker 0 (07:59 - 09:01): Yeah, there was actually, I kind of, I think because you're so close to your education when you start, you kind of were a bit idealistic about how things like sort of a multi-stage, stratified random sample would be drawn and, um, a purist approach. And I realized that in, in the pragmatic world of clients, is actually not as idealistic as, as you think it is. And that some of the research you'd look at and go, well, academically I wasn't taught to do it that way. Actually, that's how it happens. So drawing samples is a good example. And my report writing was terrible. <laugh> writing like two page summaries on advertising spend and share of voice. And I was writing it in a kind of quasi academic dissertation, <laugh> as, as opposed to being taught to write clearly and positively Mm-Hmm. <affirmative>. And I thought, um, and I haven't seen them for years and years, but I'm sure some of them would've been truly terrible. <laugh> 
 Speaker 1 (09:02 - 09:07): <laugh>. What do you think that's quite an interesting idea that that kind of, um, uh, that, 
 Speaker 0 (09:08 - 09:08): Uh, 
 Speaker 1 (09:08 - 09:22): That, I guess just the difference between, uh, academic educational research and then kind of market research out in, in the kind of business world, or at least in the Yeah. Outside of academia, let's say. Yeah. What would you say are the, the sort of key differences? 
 Speaker 0 (09:22 - 10:50): The key, well, the key differences are about what it's for, because often I think academically you are looking to, um, sort of discuss and, and, and critique a known sort of phenomena, um, and challenge it and say, you know, does the multiplier effect in economics really actually happen and do dissertation academic, using operational research to see whether or not that's the case or not. Mm-Hmm. <affirmative>. But, so a lot of academic research is around original thinking, on existing concepts to see whether they can be nudged in some way, whereas commercial market research has nothing to do with that. It's about decision making. It's about, you know, do we launch this power shower or that power shower? Okay. And if we need to communicate a price increase, these are the ways we could do it, which is the optimum one. Mm-Hmm. <affirmative>. So in the commercial world, not surprisingly, it's about organizational and business impact, and then understanding that whereas academic was more about a, a sort of a thesis around a deeper understanding, but not necessarily for any benefit, if you mean other than, other than knowledge curatorship. So I suppose academia is, is knowledge curatorship research insight in the commercial world is about business and organizational impact. Um, and they have a common route in terms of, you know, the, the, the, the, the research methods, but the purpose and application of it completely different. 
 Speaker 1 (10:50 - 11:00): Mm-Hmm mm-Hmm. Yeah. No, thank you for just bringing that to life a little bit. I think that's something that quite a few people are interested in understanding the sort of, the nuances around the differences there. Yeah. 
 Speaker 0 (11:00 - 11:26): You, you can go full circle if you get experience enough, then you can start to go back to academia and start to use it to, um, <inaudible>. But you can't do that early on. People are just saying, well, look, you just need to write a report on time that's on brief John, rather than, um, question whether or not advertising ever works <laugh> and any kind of existential phenomena, maybe just stick to the script, <laugh> <laugh>. 
 Speaker 0 (11:27 - 12:19): But yeah. And that sort of, and that was sort of 40, 40 years or so ago. So because of that, I've lived through it. One of the points you asked about was things that have been impactful in, in the life of the industry. Mm-Hmm. And there have been, I made some notes on this because I wrote an article for the MRSA few years ago on, on the paradigm shifts, really. And the biggest one, really biggest I would still say is what kind of happened around, um, very early 1980s. Okay. Up until that point, really since the post-war period, any kind of interviewing or data collection was done in either face-to-face with a lady, often a lady with a clipboard and questionnaire on, on the high street, or having a knock on the door and being interviewed in the home if it was a longer interview. 
 Speaker 0 (12:20 - 13:18): And then sometimes you might get a self completion survey through the post and you could complete it on your own and then send it back and be incentivized to be part of a prize draw. And that was really, that was the case for 30 years, really. And then telephone came. Mm-Hmm. <affirmative> and the shift from face-to-face interviewing and telephone interviewing was probably greater in my opinion, than the shift to the internet at that time, because it was seems to be revolutionary. Right. Um, because it was so much quicker and there were no interviewers that you had to send stuff out to all around the country to individual sampling points to interview. You just do it from one centralized telephone unit. So the quality control of having all the interviews in one place was much higher. Mm-Hmm. <affirmative>. And you could do the work quicker. Um, and it was cheaper for, for clients to buy until, did you notice any difference in the, the quality of respondent? 
 Speaker 0 (13:18 - 14:15): Yeah. Oh yeah. Quite often. You used to find, um, it was worked out pretty early on. That telephone was, was very good for, for speed and cost and for getting an unclustered sample across, across the nation. And very good for international research as well. If you used, um, native speakers that could all be coordinated from London, but only for quite short interviews, any interview length that started to nudge beyond 15 minutes, respondents were getting bored and it, they weren't really always giving considered answers. So it was good for polling, it was good for snapshot surveys, but for the more detailed, um, in depth market research, it requires, say, a 45 minute interview that still had to be done at home. Um, but we used to do compare and contrast results from telephone and face-to-face. And we used to find that we had a high level of don't know, response on telephone. 
 Speaker 0 (14:15 - 15:14): 'cause people didn't have the time to consider it. Um, whereas face-to-face with the interviewer present with them, there was more of an obligation to give a considered response. Mm-Hmm. <affirmative>. So that became a challenge. But then clients took the view, well, you know what, kind of don't care really. And if it's so much quicker and cheaper and faster, then, um, and telephone landline penetration was pretty much it saturation. And you can sample people using telephone directories as a sampling frame. And that became very popular and sort grew massively. And that was a significant paradigm shift. Mm-Hmm. And in response to that, the second kind of mini paradigm shift was doing the face-to-face interviews changed from using, um, a pen and paper questionnaire to something called capi, which is computer assisted personal interviewing, where you go in with basically what would've been, now we would call it like a, a, a tablet, and you could do the interview and you could do the data collection automatically. 
 Speaker 0 (15:14 - 16:11): And that came as a response of, of telephone interviewing. So that happened. And then the other mini paradigm shift was telephone was doing so well that people said that there's still people in a telephone unit phoning people up and answering the questions using a pen and paper questionnaire. And they made that all computerized and that became computer assisted telephone interviewing or ca uh, and that there was some very good CAI agencies around at the time. And, um, it was, it was very successful into the, um, into the nineties really. Um, and then the internet came and that changed everything that, you know, people just went well, issues around sample representation, but if you could get over that with waiting internet now, um, can do one thing that's telephone couldn't, which you show people stuff, right? Mm-Hmm. <affirmative> in, in detail. And you get people choose products, you show actual products in situ Mm-Hmm. 
 Speaker 0 (16:11 - 17:01): That show cars of sketches of a product Mm-Hmm. <affirmative>. And it was even cheaper and it was even quicker. And therefore people went, that's what we are going to be doing. And now most research is done online. Mm-Hmm. And did that change the business model for, you know, you mentioned that you were running <crosstalk>. Yeah. Oh, absolutely. I mean, what happened was, you, you didn't, all of a sudden you didn't necessarily have to have, if you were an agency, you didn't necessarily have to have your own field work department, the people who did the interviewing anymore. You didn't have to have your own field force or your own CAI unit. You could just sub it out to, um, any of what we now call the sort of panel exchange providers, like the since of this world or research now was, was a, was a pioneer before they then became who they became. 
 Speaker 0 (17:02 - 17:49): Um, and they would do all of that for you. They'd do the scripting, they'd do the coding, they'd do the dp, they'd do the, the actual field work, and you get the results super quick. Mm-Hmm. <affirmative>. So all of a sudden people thought, well, we don't need as an agency to have that fixed sunken cost in-house. Okay. Mm-Hmm. <affirmative>, it is a variable CLO cost, and we'll flex it as and when there's client demand. Mm-Hmm. That was massive, Dave. It really was massive. And everyone went, you know what? And we could not just do that, but we can do it anywhere in the world, you know? Um, and then as technology improved, you could start doing more advanced surveys online, like conjoint analysis and getting people to co to compare products through iterations. You can do pricing research, brand price, trade off, quite tricky stuff. 
 Speaker 0 (17:49 - 19:10): There has always been the ER of doing face-to-face, either in home or in a hall. Um, and everyone just embraced it. And it also is more accurate. And that's, that's through everyone, and people can understand why you go with a high watermark in this, because they did, um, they correctly predicted, I don't know which general election it was within the years ago, but they got it bang on Mm-Hmm. And it's the first time online had been used, and people like the traditional pulses like Maori and NOP couldn't quite understand how they had been so accurate. Mm-Hmm. And they realized that there is no interview effect. Okay. Mm-Hmm. You can be honest online. Okay. And say you're gonna vote for reform, even though, for example, you might not want to necessarily make that public knowledge to the interviewer. Mm-Hmm. The, the desire to have inter well the, the problem of interviewer bias. Whereas as a respondent, you kind of wanna present a certain type of self that went and we got a lot more honest answers. And, um, that became the sort of proof for, for internet research moving forward. Mm-Hmm. So they were so really from, from face-to-face to cat, to Catie, and then from, and then Catie to online were the three big steps with a couple of small steps in between. Mm. 
 Speaker 1 (19:10 - 19:16): Perfect. And then as you consider kind of what comes next, um, have you played with, you know, chat GPT and the like and 
 Speaker 0 (19:16 - 20:12): Oh yeah. We all have, we've all had to go and we all do what we do. I mean, the thing is, I mean, it's, it's just, it's what, you know, going back to my kind of neo academic bent, it is this sort of neo-Marxist concept of technological determinism, which is technology will determine society and you can't put the genie back in the bottle really, is essentially what a neo-Marxist would argue. Not necessarily for the greater good of society, but nonetheless the concept holds. Yeah. And now it's everywhere. I mean, it's everywhere. And everyone uses chat. GBT, everyone uses, um, the Microsoft default AI report writer. Everyone has a go and everyone's wowed by it. Mm-Hmm. But it, it, in terms of what you are doing and in terms of the insight industry, it, it just, in many ways, apart from what it does, it sort has full benefits really to a client. 
 Speaker 0 (20:12 - 21:10): Okay. And that is, and to the agency improves productivity because you can explore vast data lakes in a hundred times faster than using traditional, um, uh, micro. That, that's machine learning with ai. And often, often refer to AI as automate or, or, um, automated insight rather than, um, artificial, um, intelligence because it's more automated than anything. But productivity is huge. Okay. It really is. Um, and you can write, report some reports in, in a click of an eye Mm-Hmm. And then you can fine tune it, but there are productivity measures. So, um, that leads onto the client thinking, well, you can do it quicker just as well. It should be a cost saving to us. Mm-Hmm. And the work from the University of Leads that was well published about a year or so ago, e estimated cost reductions of clients of up to about 30% now. Mm-Hmm. 
 Speaker 0 (21:11 - 22:15): The clients will often say in their RF Qs, can you show evidence of how you're gonna save money using ai? And they expect that to be reasonably tangible. Mm-Hmm. Uh, it's cost effective. Um, and it's, it's very good at predictive analysis, in my opinion. It's very good at predicting, um, trends. Um, it can do that in a way that's automated, but it's quick, it's cheap, it's terribly accurate. Mm-Hmm. And it improves productivity, and that's just using AI to do survey design and scripting and data analysis. Mm-Hmm. It's really every touch point across the journey. And I think also it's become quite, this is where it relates to, to your endeavor, Dave, in that it's becoming sort of quietly commoditized in, in double quick time, you know? Yeah, yeah. Exceptional To have a AI as part of your, your delivery model, it's just expected 
 Speaker 1 (22:15 - 22:47): Default. Yeah. How do you think it may affect agencies in particular in the way, you know, you said that, um, when the telephone, uh, when Kati came in, uh, the, the agencies really fundamentally changed shape, um, and as you said, they kind of became more, the agencies themselves became more agile. They held on presumably to the strategic insight piece, and they kind of farmed out the legwork. 'cause that might be an oversimplification, but, um, I think that's what you were saying. Do, do you see a similar or another step change again with the agency market? 
 Speaker 0 (22:47 - 23:42): I do. I see that the, there's a sort of broader thumb or ratio of the number of full-time executives in an agency that you require to handle a certain proportion of, of client turnover and client project number based upon the traditional model of what a, a trainee or junior research exec would be doing. Everything from drafting questionnaires to writing discussion guides, to writing recruitment questionnaires for quote cas gone. Okay. So you are gonna find that the, the, the, the per capita head count in a typical medium sized agency is gonna fall by about 10 to 15%. Mm-Hmm. <affirmative>, they'll need fewer people to do it. Okay. Yep. Um, and then the people that they do have will be doing less, even, even at relatively junior levels, will be less transactional in what they do. It'll be more insight and consultative thinking because we now have the time and the, and the bandwidth to do it. 
 Speaker 0 (23:42 - 24:20): Mm-Hmm. <affirmative>. But the other two things, I think you're gonna see and see fewer people in an agency, but the caliber of the people that are in an agency will be the people who can provide the added value learning and insight that clients' demand. Mm-Hmm. And, uh, and clients want it. And that's the thing that's driving it. It's, it one of these things, it wasn't so much that agency said, we now offer an AI enabled solution for you. Would you like it sort of saying, we want your AI solution, um, give it to us. Mm-Hmm. So clients have had, agencies have had to sort of, you know, get in line and, and, and follow the <inaudible> from their clients. Mm-Hmm. 
 Speaker 1 (24:20 - 24:31): Yeah. Yeah. Absolutely. And if you were to think, uh, if you came across, uh, your graduate self having just left university and started at a research agency, uh, what would be your advice to them? 
 Speaker 0 (24:33 - 25:47): My advice to them? You see, it's a really interesting question there, and I have chatted offline to Graham about this because your, your platform begs the question of what the new breed of qualitative research is gonna be like, because the, the, the traditional model of being trained as a moderator sort of shifts a little bit. If I knew what was coming, um, I'm not sure that it would've scared me 'cause I'm not sure, because the only skills I would've had at that time would've been the skills that AI is actually going to replace. So I'd have to argue that maybe I'd become more of a consultant than a practitioner. Okay. And I wanna know whether that's something I would wanna be comfortable with. Mm-Hmm. <affirmative>, I'm naturally curious by nature, so I'd wanna know how it works and, and that would probably encourage me, but I'll be taught to remember. Um, it's the so what aspect of the insight project you're doing, not how you are doing it or how well you are doing it. It's a so what. And if you've got more time to address that key and vexing client concern, then that's probably what I'd reassure my younger self about 
 Speaker 1 (25:47 - 25:47): <laugh>. 
 Speaker 0 (25:48 - 25:48): Thank you. 
 Speaker 1 (25:49 - 25:54): Um, as you think back across your working career, like what would you say is the best piece of work advice you ever 
 Speaker 0 (25:56 - 26:42): Received? You received so many. I mean, and, and I'm not kidding. Um, so I used to do, um, I have a little list of 42 things that I've learned in 40 years of being in the industry. And, and some of them are very personal. My favorite one used to be, um, admitting you are wrong and apologizing unconditionally and an ability to laugh at your own expense are the three biggest measures of self-confidence I know of. Mm-Hmm. But the one I really liked was from my very first boss who said, look, never ever think you have to deal with a problem on your own. If you need advice, don't be afraid to ask for it. Mm-Hmm. You know, to try and do it on your own is stupidity personified. 
 Speaker 0 (26:44 - 27:18): And, um, you don't give clients your confidence. Clients give their confidence to you. And that's an interesting one. Yeah. Yeah. It's really all about not wanting to be this sort of pious, personalized PhD writing executive and to go, you know what, just ask, you know, you're not gonna be marked down in the classroom because you're relying on help. Mm-Hmm. And they, those the pieces of I've, the pieces of advice I've got, I've always passed on because they all tell me in pretty, in pretty high steam. What about you? Can you remember the best advice you got? <laugh>. 
 Speaker 1 (27:19 - 27:37): Oh, that's very good. Uh, so the one that I guess that always comes to mind is, is clear your desk <laugh>. Um, and that was because I tended, I was too much of a perfectionist and I would sort of pile things up and pile things up and I'd keep working on them and go back to them and work on some more and improving them rather than just like, get off your desk <laugh> and move on. 
 Speaker 0 (27:37 - 27:49): That's a very good one. I mean, it'd be interested to see what, what Danny and Parvin and Graham think. Well, theirs are, I'm sure Graham's a few interesting ones. Yeah. Yeah. And, um, you also asked me about a, a favorite project or a 
 Speaker 1 (27:49 - 27:53): Yeah, yeah. I was gonna come back to that. What was your your favorite job or project? And, and Oh, 
 Speaker 0 (27:53 - 28:08): This is a real standout. And this happened relatively late in my career while, uh, just as I became chief executive. This was about 20 years ago. Um, and I had a key client, um, who was a lovely man, uncle Simon Thomas. I'm allowed to mention Z because I said it. And then Simon Thomas is billionaire. 
 Speaker 1 (28:09 - 28:09): Right. Wow. 
 Speaker 0 (28:09 - 28:43): And he made his money in, um, bingo across the country. And he decided that he would buy and completely regenerate the HIPA drone building in lesser square and, and turn it into the casino that it is now. Right. And it used to be Peter Stringfellow's second nightclub. And we went, we went to have a look at it and oh God, it's such a mess. He was gonna spend, you know, 25 million doing it up and going back to the plaster and making it the original Hippodrome inside and outside and a different type of, uh, super casino really? 
 Speaker 1 (28:43 - 28:44): Mm. 
 Speaker 0 (28:45 - 29:27): And he got, um, all the local casinos in the area, and there were a few, it all objected. And we had to, um, establish whether the only reason that they would get a license to have this mega casino is if they could prove beyond doubt, incremental demand. Mm-Hmm. <affirmative>. So it wouldn't be cannibalizing demand from the existing ones, it'd be bringing new people in. Yeah. And we did quite a big research piece, and it got presented by me in court, the appeal court. So I was cross examined by different barristers all representing the conclave of, um, different existing competitive casino owners. And I was cross examined. That's, yeah. 
 Speaker 1 (29:27 - 29:27): Yeah. 
 Speaker 0 (29:28 - 29:38): And we coached as well because when you get asked a question by, even now, you get asked a question by the barrister saying, isn't it true Mr. Priest that this research is a low rubbish 
 Speaker 1 (29:38 - 29:38): <laugh> 
 Speaker 0 (29:39 - 30:25): Turn and give your answer to the bench? You don't answer the barer, you have to turn the answer to the bench. Mm-Hmm. And it's fascinating because I had really had to prep for it and, and I remember doing half <inaudible> and we won. Nice. We won. And it was one of those things where you get an objective verification that the work was good and it it was good. Mm-Hmm. And, and now a lifelong VIP member of Hip <laugh>, I do, you know, what's in my dying shame? 'cause I'm not really into bank gambling. I've never been, but Simon always says I should go. Mm-Hmm. That was, that was for theater and drama and getting, uh, uh, getting a third party stamp of approval and them getting the green light to do the casino was great. Really. 
 Speaker 1 (30:25 - 30:33): I mean, what amazing validation, but also like, um, to have your work stand up under that type of scrutiny. Do you know what I mean? Is really quite phenomenal. 
 Speaker 0 (30:33 - 31:36): It was terrible. I mean, they, they, the barrers were really good, but they didn't really know. They said, oh, well we think it's leading. And you know, you said you're describing this as if it were a breakfast cereal. Mr. Priest's saying it's 'cause this Hippodrome hadn't yet existed. So we were explaining the concept and other Debranded concepts. I said, look at its adjective three. I said, they are statements of fact as briefed into our client. We haven't said it's gonna be wonderful. We just said it will be the biggest in the uk, which is a fact. And then there was some put and call, put and call and then, um, other people gave evidence of other aspects and they, they got it through and it became, it's become a magnificent success as well. In fact, Simon is now chair of the association of all the casino owners in that area. So they're all friends, <laugh>, and they all benefited 'cause people come in, yeah. Come in to the big casino experience, they go in there for an hour, maybe don't do well, or they do well and they go, we'll try somewhere else. Mm-Hmm. <affirmative> and go to another casino. So they did actually raise demand as well as bringing in incremental demand. So everyone won and everyone ended up being friends, which is nice. 
 Speaker 1 (31:36 - 31:55): Nice. Very good. Yes. Um, and then the thing that I'll try and end, end on is the kind of, um, if there's one thing you'd like the audience to take away from the conversation to be, you know, from the conversation today, what would you like that to be? Um, is there anything in particular that you sort of want to uh, um, yeah, you would like to have sort of on the 
 Speaker 0 (31:55 - 33:01): Record? I think on the AI aspect, yeah. There's no, there's no resistance. Interestingly, because often when you do, when there's change, Dave, there's always resistance. 'cause people, whoever they are, who've got their things on the switch, you know, you're changing their whole way of life and they go batshit crazy. Okay. Mm-Hmm. <affirmative>. Um, but no one's doing that because everyone is seeing the benefits. Mm. It's scary for some people to see what AI can genuinely do. Even it's early sort of formative stage. Whenever there's any kind of change through technology, people tend to over steer one way or the other, thinking it's gonna be great or, or terrible. But there isn't that. Um, because practitioners of insight see the benefit in terms of productivity and speed Mm-Hmm. And clients see the benefit in terms of accuracy and depth and cost. Mm-Hmm. And it's become, it's become the, the, the new model. Mm-Hmm. So what I would say to people is it's not something to be feared or resisted because everyone should win. Mm-Hmm. Um, and that's the key message I'd like to leave you with. 
 Speaker 1 (33:02 - 33:40): Hmm. Cool. No, fab. Pretty good. Um, yeah, no, that's gonna be great. Thank you very much. Um, I'll, um, I'll kind of, uh, I'll re I will probably follow the original order. Okay. So I'll kind of try and, um, uh, sort of go back through the notes from today and just think about how to kind of structure and order things. I probably will, um, do the favorite job project earlier on in the, in the conversation. I think it's really interesting. Uh, following on from that, then going into the sort of the impact on your working life and the way that it's kind of changed. Um, we didn't really dwell too much on like, other things that you think could be done differently or better, but we, we kind of covered that, that, anyway, 
 Speaker 0 (33:41 - 33:49): I think AI is, is is kind of AI with machine learning is kind of, is, is kind of doing that. Mm. Well I think in terms of me then there's um, I guess your 
 Speaker 1 (33:50 - 34:03): Specific expertise at the moment, is there anything that's particularly pertinent to agencies that are trying to sell? Do you see what I mean? Or anything that you think they need to be doing different? Like, I don't know if that's quite the right thing to go into, but I dunno, maybe there's something that 
 Speaker 0 (34:04 - 34:24): Maybe not. I think maybe more what I would suggest when we do our kind of live recording, which is in a few days time, isn't it? Mm-Hmm. <affirmative>. Exactly. We're planning to do it, do individuals and then do an edited version of everyone talking rather than everyone being on at the same time. Um, I think that's what you are planning to do, is that not right? So I'm gonna be speaking to you in a week's time. 
 Speaker 1 (34:24 - 34:25): Yeah, yeah. 
 Speaker 0 (34:25 - 34:27): You're gonna be speaking to somebody else properly. Yeah. 
 Speaker 1 (34:27 - 34:31): Yeah. I'm at the moment just doing them individually. I was gonna ask you as well actually though, if 
 Speaker 0 (34:31 - 34:31): <inaudible> 
 Speaker 1 (34:32 - 34:47): Yeah. I was gonna ask you like maybe if, if there was anyone else that you thought would be good to speak to or if, if like there was sort of two or a group of two or three people who might have a speci have an interesting conversation on a specific topic, um, at some point in the future as well. That was just 
 Speaker 0 (34:47 - 35:35): Yeah. Yeah. I'll, I'll, I'll, I'll have a I'll have a think on that, um, because that might be a useful way to go, but maybe you could talk a bit. No, it's a suggestion. Maybe, um, when we do the, um, the second take on this and for the other, other guests as well on the council is specifically around AI and Qual, right? Yeah. Which is the, not the elephant in the room, but as it as it relates so obviously to beings. Yeah. Yeah. The challenge is specifically because that's not as, this is one of the reasons why your venture has come into existence, I think. Mm-Hmm. Um, as one of the generic benefits of ai, um, in insight, how it specifically applies to qual develops and goes beyond some of the things you mentioned in your website as well. Mm-Hmm. That might be a, a, a useful thing to include. Um, 
 Speaker 1 (35:36 - 35:41): Yeah, yeah. Go, go on, go on then tell me a little bit more about what you are Yeah. What you're thinking there in terms of, um, 
 Speaker 0 (35:41 - 36:04): Well, if, if you, if you use beings, and as I understand it currently, and forgive me if I've got gaps in knowledge, it, you know, it can recruit, it can recruit the, the, the group or the group discussion or the community for you. It can construct the, uh, your AI assistant can help construct the, the moderator guide or the discussion guide moderate the groups for you. Is that correct as well? 
 Speaker 1 (36:04 - 36:05): Yeah. Yeah. 
 Speaker 0 (36:05 - 37:11): Um, and it can give you, um, either transcripts or analysis of the transcripts and comes through with a summary thing. Hmm. The, the challenge, the thing, the thing that, um, Graham would say, and I would say as well, is that the nuances of qualitative research Mm-Hmm. Are, are revered by clients. Mm-Hmm. It's often, otherwise what you can get is a, is a content analysis Yeah. Of what's being said. And that's not what qualitative is traditionally. It's what people don't say that's important. Mm-Hmm. It's, it's, it's how difficult they find things to talk about that's important. It's, it's how they say what they say is important. Mm-Hmm. You know, and 70% of communication is nonverbal. Mm-Hmm. So their facial and their hand expressions around what they're saying. Mm-Hmm. And it, in a traditional qualitative way, you, if the client was observing in a, in a, in a viewing lab, they would say, yeah, look, obviously they're finding this difficult saying stuff, but it is generalized nonsense. 
 Speaker 0 (37:11 - 37:52): Okay. They're really struggling with this concept, let's try another route. Mm-Hmm. <affirmative>. Um, and that's where upper end qual the, the, the parts which people like Graham Hall does or like Acacia Avenue would do. That's really where they have the skills, particularly around nuances in terms of understanding brands and advertising concepts. Mm-Hmm. <affirmative>. So it's around how ai, how far AI can get you on that Mm-Hmm. <affirmative> and then what the moderator can do to fill in the gaps based upon, well in my experience, I think they're just saying stuff which platitudinous, it's not really insight. Um, that's things that, that's one of the things that I would suggest you No, 
 Speaker 1 (37:53 - 39:02): Yeah, no, that's super interesting. Let me try and draw out a question that will sort of play into that. Um, again, I don't really want this to necessarily be about promoting beings in any way, shape or form. It's really about hearing from expertise in the industry. Mm-Hmm. <affirmative>, um, you know, but you sort to answer your question, like, the point of it of my business being called beings is 'cause it's about augmenting what the human being can do. Mm. Um, and my sort of vision for the product is that it can do all the other stuff except for that core piece of, of insight. Do you see what I mean? Um, 'cause I think you're exactly right. Like AI can do a generic level of, um, of, you know, of word analysis. Do you see what I mean? And Yeah, I think like in terms of the other parts of the process, like at the moment we don't really, we haven't led into the recruitment side yet. You know, there's quite a big industry out there that does that already. Mm-Hmm. <affirmative>. And so one of my questions is, um, sort of generally in my head at the moment, not not for this podcast, I mean, but one of my questions is, is it worth trying to sort of get into that recruitment world? Is that a real problem that people wanna solve? Or actually are there like a million solutions out there already? And so there's no, you know, there's no <crosstalk>. If 
 Speaker 0 (39:02 - 39:28): You can, if you can, if you've got, um, if you can plug into the, to the exchanges and you can recruit automatically, so you wanna, you wanna recruit a, a, a research community of, of, of, of 20 people, of which you're gonna get 15 live and they've gotta be this profile, then they will do it for you. But if, if there is a, I forget the word, is it an a SI or whatever it is that can connect your, your 
 Speaker 1 (39:28 - 39:29): API 
 Speaker 0 (39:29 - 40:15): Yeah. If that can connect that to the, to the, to the, um, to the sample exchanges, like, like, uh, syns or that would be useful to do. But one, one of the things we found when we, we did, I did, my agency did a lot of qualitative research back in the day, and there'd be a lot of the data collection or the field workers we call, you go to groups, physically travel, you do it. Now it's mostly know 50 50 online, 50 50 face to face. But you get a lot of data, you get a lot of transcripted analysis and you kinda had to make sense of what it meant, not what was said. Okay. Mm-Hmm. So people would typically, the two moderators working on a project would typically be in a room for a day. Usually the boardroom get all their pieces of paper out and they go, what does this all mean? 
 Speaker 0 (40:15 - 41:04): Mm-Hmm. But then when they've got the big themes, then they would populate it with the kind of content, if you like. Mm-Hmm. So if, and that takes lots of time, very laid, intensive qual, and it's not very scalable, which is why I think beings is, is an interesting addition to the market. Mm-Hmm. If, if, if, if AI empowered qual as a platform can create more time for the more data to look and go, what does this mean? Mm-Hmm. 'cause that's what clients are buying. And with a few illustrative quotes or, or videos, okay. If you can do that, and that's a smart move because that's where the, the brain power needs time. And if you can provide time by using the efficiencies of, of a platform like yours mm-Hmm. That's really where I think you get traction. Mm-Hmm. 
 Speaker 1 (41:04 - 42:23): Yeah. Yeah. Um, yeah. No, that's brilliant. Thank you. Um, the technically, I think what's fascinating about large language models, um, fascinating to a technologist like me, um, is that what an LLM is fundamentally doing is comparing semantic meaning. So it's not actually trying to, it doesn't care what words you've used, it cares what you mean by those words that you've used, but you're still absolutely right. It only, it currently it can only get so far because it needs to understand context. Mm. It needs to have a much broader picture to be able to get to the right semantic meaning. Do you see what I mean? Yeah. What it technically, what it actually does is it doesn't actually, it doesn't even think about whole words. It chops it all up into numbers, represents it as numbers within a database, or represents the meaning of the numbers within a database, and then it looks for the next nearest Mm. To then determine whether it means the same thing or not. So it's, it's, um, yeah, it's, it's, it ought to be able to be really good at qual, but I think you're exactly right. Um, at the moment it, it, we can't combine the facial analysis with the words yet, but obviously technically we will be able to, um, in future, um, we can't read somebody's body language quite yet. But again, over time I think we'll be able to build these different elements in which will give a much stronger, 
 Speaker 0 (42:23 - 43:10): Mean, a good example before we finish is, is how com started the sixties, but there's a cake mix, famous case study cake mix. I dunno who made it. Some American cereal partners type company. He made a cake mix in the, in the fifties, which is Consumer America housewife home husband working. Okay. So their role is Housemaker, he bought House is is Cake mix, which was a box and all you did is our water stir it Baked. Yeah. And it pre-tested brilliantly. Yeah, absolutely. Fantastic. Never sold. Yeah. Never sold <laugh> and it couldn't work out. Why? Yeah. <inaudible>, it was going great, so All right. Things, convenience. It was only through the most subtlest of qual, but they able to work out that it was actually too easy and Housewives were feeding. Oh, I 
 Speaker 1 (43:10 - 43:15): Know this one. Yeah. Yeah. This is the one where like they make, they changed it. So you had to add your own eggs so you don't add 
 Speaker 0 (43:15 - 43:46): Your milk and had your own egg, and they put a little egg and all of a sudden, as soon as you have to add an egg, then it became a bit more skillful and it said flu and that nuance, which you didn't quite get to until you knew to say, actually, is it, do you feel a bit threatened by this? And they were going, actually, yeah, we do. That's the, those sort of breakthrough moments. And that more the thinking is what is what clients look for. So that <inaudible> that. Cool, cool, cool. Right. You've disappeared, Dave. Oh, 
 Speaker 1 (43:46 - 43:47): Sorry. Hello? Hello? 
 Speaker 0 (43:48 - 43:53): Back again? Yeah, I'm back. Cool. Fabulous. Thank you. Anything for me? Or are we done? 
 Speaker 1 (43:53 - 44:04): Uh, no, that's brilliant. Thank you very much. I do appreciate that. I'll share some notes with you and, um, just sort of a final kind of structure. Um, and, uh, yeah, I look forward to talking to you. Uh, I think 
 Speaker 0 (44:04 - 44:16): It was next week, I think. Yeah. Yeah, I think so. Yes. It's booked in. And, and good luck chatting with everybody else. You ever I, you've met them all now. Oh, they're lovely. But there's an eclectic blend. I think you've got a good, good selection day. Wonderful. I love you holiday weekend. Thank you. Enjoy 
 Speaker 1 (44:16 - 44:17): Your weekend. Bye-Bye. 
 Speaker 0 (44:17 - 44:17): Bye.

---
*Converted from original Word document.*

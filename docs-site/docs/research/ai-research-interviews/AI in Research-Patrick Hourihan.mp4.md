  
**Speaker 0 (6:15 \- 2:40:15):** \<inaudible\> insights@uhbeings.com. Uh, we are developing, uh, uh, ai, uh, products for, for market research. 

**Speaker 1 (3:02:25 \- 3:08:15):** Great. 

**Speaker 0 (3:18:35 \- 5:48:15):** And, uh, here we have another participant called Data, which is our note taker work by our company. So, do you mind if I keep it here to record our meeting? 

**Speaker 1 (6:07:15 \- 7:24:45):** Yeah, that's fine. Do you need me on camera in this or can I turn off the camera? 

**Speaker 0 (7:35:15 \- 8:09:25):** Well, that would be great if you can keep it, 

**Speaker 1 (8:31:05 \- 8:41:15):** Keep it on. 

**Speaker 0 (8:48:25 \- 9:19:15):** Yeah. Yeah. If you can keep it on 

**Speaker 1 (9:35:35 \- 12:47:15):** Is the, um, is, how's the data gonna be used? Just off the back of it, just so that I understand, like, is there, I, I'd like to think any video and audio is, is confidential and proprietary. 

**Speaker 0 (12:56:05 \- 17:32:35):** It'll be strictly for our internal use only by the product team. We are basically just three, uh, CEO of the company, Dave, and then one more product manager. It's basically just by the, uh, used by the product team. It'll be used only for our internal discussions. Nothing, uh, public. 

**Speaker 1 (17:44:25 \- 17:59:55):** Okay. Sounds good. 

**Speaker 0 (18:13:05 \- 19:32:35):** Yeah. But if, if you have any problem, yeah. You can, uh, switch off the video, uh, as you prefer. Uh, 

**Speaker 1 (19:54:15 \- 20:04:35):** Sounds good. 

**Speaker 0 (20:18:25 \- 25:29:35):** Okay, great. Thanks. Uh, so, uh, can, can we please start with the, a little bit introduction about your work, uh, think what kind of jobs you do, and if you can also explain a little bit more about your day-to-Day activities and if, uh, you are using ai, uh, for, for any of those jobs. 

**Speaker 1 (25:39:25 \- 44:53:55):** Yeah. Um, my name is Patrick Rahan. I am a senior director in the Global Analytics and Measurement team at NBCU. Um, my, I've worked in research for about 20 years at different media companies, the BBC at Yahoo, and at NBC Universal, as well as some time freelancing and agency site. Um, uh, my role fundamentally, I'm not gonna talk about the details of my role too much 'cause it's, you know, within, within NBCU, but, um, my main focus is understanding streaming behaviors, so not broadcast tv, but really the, um, the emergence in the media landscape of, of, of global streaming platforms and trying to understand the relationships that consumers have with them and with the content that sits in those platforms. Um, that research can take a number of different forms. Um, as with any international broadcaster, to be honest, I don't think this isn't proprietary, but there is data analysis, there is focus groups, there is, uh, quantitative surveys. 

**Speaker 1 (45:00:55 \- 66:24:25):** Um, there are passive listening tools. And most roles in media and, and mine included, will include a combination of analysis across all of those things. Um, I am working on a, um, we are actively thinking about AI at the moment. I think the challenge with ai, if I'm honest, is if we go back two years and we think about, um, pre chat GPT and pre the gen AI explosion, there were lots of tools that already out there that were talking about, um, machine learning and data automation. And it's quite hard to tell which of these tools now are, um, are actually meaningfully AI powered, you know, and how different are they to what went on in the past. And also it's really just, it's, it's, I read a, a piece on LinkedIn the other day, which is really interesting, which basically said, if you are pitching a new company or a new business or a new product and you don't mention ai, then is it gonna feel like a gap to whoever your audience is? 

**Speaker 1 (66:24:25 \- 85:19:15):** Because you shouldn't need the words ai just to make it sound relevant. So I think there's a lot, personally, I think there's a lot of smoke and mirrors around Yeah. What does constitute AI and what doesn't? And ultimately what, as a, as a researcher and as a leader of a research team, what I'm looking for is tools that greatly enhance our ability to create insight and to interpret data and to find solutions to challenges. Um, I guess I think about there's a, there's a few different ways of thinking about it. I mean, you are, you are asking me specifically about AI from a research perspective, but there is also AI that can enhance our business overall, which makes research easier or harder. So, for example, there's lots of, um, one of the areas within content creation and NBC universal obviously creates content like Yep. Um, uh, is about the ability to auto translate content or the ability to lip sync content in a much shorter space of time and a more efficient space of time. 

**Speaker 1 (85:29:35 \- 113:16:55):** And none of that is really about, really about market research, but all of it is about the product that we help to support. So I know today we're not really talking about that, but the, the ways in which we've used AI tend to be, um, using, um, some tools, um, like, I'm not gonna say that they are, but like chat PT or like, um, copilot to, um, enhance survey design or to, um, support enhance, um, uh, discussion guide design or, um, and that would be more, that would be an in-house usage. From an external perspective, it's probably more what we'd like to see are meaningful tools that allow us to, um, manipulate and dissect large, large sets of streaming data faster and more efficiently. I think we're looking for tools that allow us to, um, synthesize data wherever possible, whether that's, um, just fusing data, two different data sets that are relevant to each other, or even fusing more synthetically with other data sets that may, you know, that you are looking to do some predictive modeling of off of. And I think it's quite hard in that whole area about data interpretation to understand, you know, you've gotta do a full product analysis to really decide whether you wanna buy some of those things. Um, 

**Speaker 0 (113:27:25 \- 113:32:15):** Yeah, 

**Speaker 1 (114:03:55 \- 114:38:25):** Sorry, it was a slight ramble for a while. 

**Speaker 0 (114:48:05 \- 128:23:25):** No, no, I, I really appreciate that. Thank you very much for covering a lot of topics. I totally agree with you in terms of, uh, the use of, uh, AI that if people are appropriately using it or not. My background is from data science and machine learning and computational modeling. And, uh, I, I totally agree that a lot of things that are pure automation are sold as the AI now. It's not really ai, uh, but yeah. Uh, the need that you mentioned about synthesize, we are, uh, that's also one of our goal to develop a synthesize tool that will help with the data analysis and, uh, using AI to drive more insights from your data. So could you please tell me a little bit more, when you say data, are you talking about qualitative data or quantitative data? Uh, and, and how much ai, uh, are currently trying to use in data analysis? 

**Speaker 1 (128:42:35 \- 151:36:55):** Not that much. Mm-Hmm. \<affirmative\>, um, it is the, it's probably 80 20 in terms of the data that we use towards quantitative data. Uh, either be about viewership or about subscription or about, um, or maybe third party data. Um, and qual data, yeah, it's probably 20% or even less, maybe 10% of the time. Um, it could be open text verbatims, but we do commission qualitative research, IE focus groups or debts or, um, expert interviews and those kind of things. Um, the reason that, I mean, at the moment we, if our business tools of choice, um, are like, like, like most companies, you know, it's tends to be Microsoft or another, another company there we're be implementing some of their AI improvement into what we do on a day-to-day basis, just because that's an enterprise deal. But we're not using too many specific tools. We're more at the exploratory stage. Mm-Hmm. \<affirmative\>, um, probably for the reasons that I've already discussed, which are, it's difficult to tell what's a meaningful data synthesis tool versus what isn't until we do, um, some broader assessments basically. 

**Speaker 0 (152:01:25 \- 158:54:35):** Right. Thanks. And, uh, if you want to know a bit more about qualitative research, uh, and are you using, uh, any, uh, services by any research agency that you will tell them, uh, do this kind of stuff, or you will have to organize, uh, and plan those research project by yourself and then recruit the participant and talk to customers? How do you carry that? 

**Speaker 1 (159:06:25 \- 170:31:25):** Yeah, we, we don't, um, we tend to commission qual agency to run the research, run the field work off off the back of an RFP, but as part of that pitch process, you know, there will be AI related tools that will be part of the methodology that will be chosen. And, you know, it's usually a competitive pitch, so they will have an influence in terms of, um, what to do. And the, our regular agencies that we work with on some of that stuff have, have actively built in. So it's almost secondary AI usage because if the agencies we are using have adopted certain tools that are helping them become more efficient, and that's obviously helping us too. 

**Speaker 0 (170:47:25 \- 174:08:15):** Yeah. Great. And, uh, in terms of, uh, data analysis, so they are probably doing all the data analysis and, uh, can I ask what kind of information they hand it back to you and in what formats? 

**Speaker 1 (174:25:55 \- 187:27:05):** Uh, PowerPoint, um, usually it's, you know, transcripts and, um, and video footage we can always get hold of, but because we are, we usually ask for full service qualitative support. It would be, um, PowerPoint and maybe Word document summary. Mm-Hmm. \<affirmative\>. So, you know, there could be, um, if we get all of the videos and Vox pops and everything, then that obviously that's ripe for, um, ai, um, sort of metadata exploration, I guess in terms of, we were looking for certain sound bites within a, within a, um, hour and a half focus group that could be helpful, but that isn't something that we've done so far. 

**Speaker 0 (187:38:35 \- 190:33:25):** Yeah. And, uh, do they also provide you some information about these sentiment analysis, like getting the tone of the discussion or those kind of things? 

**Speaker 1 (190:53:45 \- 197:26:35):** Uh, they do. I mean, that would be in the final analysis, but that would be based on human, um, human analysis rather than a, an AI system telling them that it would be, um, yeah, that would be, we, we wouldn't get a sentiment analysis alongside it. It would be just something that would be included. 

**Speaker 0 (197:35:35 \- 203:21:35):** Mm-Hmm. \<affirmative\>, uh, how do they decide about the preferred methods for data collection? That if they have to run a survey or if they have to do the video recording, do you usually tell them or you tell them the higher level requirement and then they are free to choose whatever way they feel confident in then just Yeah, how, 

**Speaker 1 (203:36:45 \- 215:51:05):** Yeah. A high level requirement usually, but, you know, preferred methodology, we are, you know, still very well versed across all research methodologies and we'd usually guide towards what we would expect to see within the RFP and then, um, after that, um, you know, the agency can choose, but we expect them to choose the methodology. It works best for the project, obviously, and that will be part of the competitive process. So, you know, if you, um, if you, uh, yeah, if you, if if you pitch the wrong approach or maybe they're not, not, not the optimal approach, then you know, you're less likely to be chosen. 

**Speaker 0 (216:00:05 \- 224:13:15):** Mm-Hmm, \<affirmative\>. Alright. Thanks. And, uh, so once you're getting the data and they're handing over you the summary and, uh, the PowerPoint, so do you usually tell them that, uh, this should be their target audience that you want to talk to management board or you want to talk to other qualitative researcher under your group? Do they give you, uh, optimized summaries or slides for different target groups, or it's always just a one generic result? 

**Speaker 1 (224:22:35 \- 236:12:25):** I mean, it depends on the project, so absolutely. We do have sort of persona build outs from qual research, but, um, we can talk about if you, if you want to talk about Quant, we can talk about quant research because the outputs are, are different and probably more detailed than what we, we tend to get a strategic insight output from qual and stick to, and we don't get, uh, we, if we request it, we'll get sort of additional persona analysis. But it's, it's been more the traditional outputs up to now basically, which is a narrative around trying to answer the research objectives that we've put in place in the RFP. 

**Speaker 0 (236:34:55 \- 242:40:45):** Right. Thanks. No, I totally understand that there is not like a hundred percent clearly very well defined boundary between two research and maybe in the same project you might need to do a bit of both quantitative or qualitative. Right. And then how do you, uh, would you like to comment on the use of AI for quantitative research as well? How much are you using or you are exploring or Yeah, what would, 

**Speaker 1 (242:43:45 \- 255:43:55):** So, so again, if, if it's a commission project, we'd usually get some kind of insights output or dashboard and or dashboard, um, in some business intelligence tool. But also, um, we would typically get, um, uh, a full data set which either we can, um, analyze and put into our data warehouse or we can, um, analyze it in Excel or, or Power Query, um, using Power Query if it's a big file. But the, we are not at the stage of really combining that data with anything else. It usually stays within the confines of that project. Mm-Hmm, 

**Speaker 0 (255:45:15 \- 256:34:15):** \<affirmative\> and, uh, 

**Speaker 1 (257:08:25 \- 275:21:35):** Sorry, actually, so that would be commissioned quant research, but the, but the bulk of what we do is non-commissioned, which would be just data that we have access to Mm-Hmm. By either first, second, or third party. Either our data, our partner's data for our content that sits on their platform or third party altogether. And that's the opportunity area around ai. And that's where we have large data warehouse capacity to hold different, um, different sets of, um, viewership data really to help us understand how content is working and what are the, um, metrics of success and that kind of thing. Um, and because those data sets are quite disparate and can, can be quite different, that's where there is always more of an opportunity to create efficiencies or for, or for us to really minimize the time it takes to data clean, to add relevant metadata and to distill that into something that a researcher can just take away and go, okay, I'm gonna analyze this now. 

**Speaker 0 (275:47:55 \- 284:15:55):** Right. Thanks. And, uh, for data visualization in general, uh, could you please comment on the, the, the ways, different ways to represent that data? Like how, uh, I mean they gave you summaries and then, uh, for quantitative data they can get, they can present it in some different forms. So what are the mostly used forms to, for data visualization? Like a graphs, charts, uh, or summaries or, uh, or, or detailed dashboards, or how do they hand it over to you? 

**Speaker 1 (284:33:55 \- 287:18:55):** So is it, are you talking specifically about a commission piece of research while we've worked with a research agency? Or are you talking about any data analysis that could be done internally? 

**Speaker 0 (287:27:35 \- 288:07:35):** I think you can talk about like both. Yeah. 

**Speaker 1 (288:26:35 \- 289:27:35):** And so commissions, can you just repeat your question briefly? 

**Speaker 0 (289:31:05 \- 295:43:35):** Sorry. Uh, yeah, so I mean, for data visualization, uh, what are the most common ways, uh, to look at the data? They giving you some link to your dashboard where you will see graphs, charts and summaries or, or, or, or mostly in just words like transcripts. So what kind of visualization information you get in both projects. 

**Speaker 1 (295:52:35 \- 314:15:25):** Yep. Uh, commission research primarily two ways. PowerPoint and, um, business intelligence dashboards. So business intelligence dashboards to be able to track data over time and to be able to slice and dice both for researchers and stakeholders. But in terms of PowerPoint, it's like, usually if we commission, we commission with a very specific objective in mind and we wanna see the answers to that objective, uh, narrated through an insight story that's usually, basically usually still comes in PowerPoint and will probably still be coming in PowerPoint in 10 years time. So, um, 'cause it's a very useful visual medium, um, about the, um, yeah, you know, sometimes yes, we still use lots of different types of charts. Yes, we use word clouds. Um, you know, we try and, um, increase the visual aesthetic within PowerPoint wherever possible. I use imagery, et cetera. In, um, dashboards, it's really built around usable tools. 

**Speaker 1 (314:23:05 \- 337:22:15):** So we don't want, we want something, not, not all of the dashboards will be used by researchers. They'll just be used by data literate, um, stakeholders and employees, you know, not necessarily in the research team. So you have to build them for people that they're actually gonna be able to utilize. So simple, clean, visual effective, um, other priorities about how those dashboards would work? Um, internally, um, if it's a report, if it's like an insight report, it would again, usually be in PowerPoint. But again, there, there's basically two main outputs now. Um, well, sorry, three, um, word is used rarely, you know, sometimes, but rarely as a, as an analysis output. But it would be either a business intelligence tool like Tableau, power bi, or PowerPoint or Excel. And Excel would be the least visual, but the fastest route to the data. So it might be a, a lower value request where we're basically providing data. Business intelligence tools tend to be for longer periods of time. Mm-Hmm. \<affirmative\> PowerPoint tends to be for, um, bespoke report outputs, storytelling, and, um, you know, a deeper understanding of a particular topic. 

**Speaker 0 (337:43:45 \- 344:04:05):** Right. Yeah. Thanks Laurie. That sounds very interesting. And, uh, particularly for your role, uh, are you using any AI tools to when, when you have meeting with people to get automated transcription or summaries or notes or to perform some kind of analysis, do you use any AI tool there for your job? Yeah, 

**Speaker 1 (344:14:05 \- 362:20:55):** I mean the, they, they're not research specific I'd say. So just because of the, um, because of the types of tools that we have baked into the company at large, those things, like in meetings we have, like your tool here, ada, we have transcription, capturing technology within meetings, um, obviously recording within meetings, there is some synthesis of meetings that happens, but all of these, I'm not saying are applying directly to, to market research or to an audience research project. Um, so less so that it feels like we're, I think the way our position in the company, in way in the international research team would be, we are just getting to a point with AI tools that some of them, some of them feel meaningfully useful and should create greater processes, but we are, um, taking baby steps into that world right now, basically. Yeah. 

**Speaker 0 (362:40:45 \- 366:30:35):** Right. Thanks. And, uh, these transcriptions of summaries provided by those tools, uh, how likely are you gonna trust it? Are they usually reliable or you wish that, uh, this could have been better? 

**Speaker 1 (366:56:15 \- 375:24:35):** I mean, that's a good point. Um, I haven't used them too much because I, I don't, I feel like I, my my process isn't always about reading a transcript after a meeting. My process is usually about, um, writing down key points within a meeting. I'm just a, I'm just a writer, so, um, I know I might not capture every moment at the meeting, but I like to think I'd distill down the key points. Um, yeah, I'd, I'd, I'd use it for a meeting that I had a transcription for where I wanted to go back over some old notes. Mm-Hmm. \<affirmative\>, uh, yeah. 

**Speaker 0 (375:36:15 \- 379:36:05):** Right. Thanks. And from ethical consideration point of view, uh, do you see any ethical challenge that that could arise because of the increased users of AI in either in market research or in general, that, that you would like to highlight? 

**Speaker 1 (379:46:05 \- 411:56:25):** A hundred percent. Um, you know, incorrect data, because models are based on what's out there and what is out there can be in incorrect data. Um, you know, the, the new apps chat, GPT copilot have usually got health warnings within them to say, um, you know, essentially data may not be accurate or insight may not be accurate. Um, please check, but that's a bit like teas and C'S in a legal document. It's like when you're signing up to buy something, quite a lot of the time you'll skip past the T's and C's in the legal document. You'll just sign up to the product that you want to get. So the tricky thing is that we are, um, AI is now out of the box essentially. And, um, people will, a, a proportion of users will just believe whatever they get and use that. And that is, and as a researcher, as working in a team of researchers, that's not how collectively we work, but we don't reflect all of the users of, of, um, these new tools. So the danger is amongst, you know, certain sectors of users that their sort of threshold for validation's much lower. Um, you know, this is, this is all stuff, you know, and I'm sure you are aware of too. It's what it's, um, so yeah, the big and scary arguments I think are quite big and quite scary, but just simply the, the job of a researcher is, um, trying to get to that grain of truth. And so any, any product that might take you away from the grain of truth is a concern basically. Mm-Hmm. 

**Speaker 0 (411:57:05 \- 419:44:25):** \<affirmative\>, right. Yeah, totally agree. Yeah, that's very valid, uh, concern. Uh, about, uh, so now, uh, I'm going back to the data analysis part again. Um, when we talk about qualitative data analysis or quantitative and select, you are getting the end result for qualitative, uh, do you have like in-house expertise to run qualitative research or quantitative research, uh, in your company as well where you don't have to ask the other companies? 

**Speaker 1 (420:06:25 \- 421:18:45):** Yes. Um, quant, yes. Qual maybe in the US but not internationally. 

**Speaker 0 (421:41:05 \- 426:16:25):** And, uh, do you see an opportunity of, uh, increasing the use of AI in quantitative analysis as well, or providing some sort of automation where the manual work could be decreased or, or if you want to give some examples how it could be achieved? 

**Speaker 1 (426:35:45 \- 450:17:25):** I think like the, the opportunities in quant analysis are, um, around data processing, data tagging. So we, we, the metadata involved in media entertainment is extremely valuable, but often doesn't come as within your data. And it is challenging for everyone, I think. So improvements in metadata and fusion of metadata would be hugely useful because some of that work still put takes place manually to this day. Um, I think it's less interesting to think about a AI product that gives you the answer to the question, because I still think that you can't skip past human distillation of a human contextual understanding of whatever the business challenge is, um, unless you very precisely guide your tool through every step that you wanted to do, and it still may make, make mistakes. So I feel a bit like AI's there to do the heavy lifting, to get the data in the shape that you need it to be in, and then for, um, uh, research specialists to come in and, you know, ultimately do the last five or 10% if AI can, can reduce the amount of human interact, human effort, um, to get the data into the shape you want it in. 

**Speaker 1 (450:36:05 \- 452:53:25):** I still think that's, yeah, I mean it's, yeah, it feels like, um, quite an old problem, but it's a very real problem still, you know, 

**Speaker 0 (453:10:05 \- 457:11:45):** And, uh, when you talk about the manual understanding of text or, uh, or the sentiment in general, are we talk, are we talking about, uh, coding and tagging that's like manually, uh, interfaced with the, the information that you're getting 

**Speaker 1 (457:18:15 \- 461:27:55):** Sometimes? Yep. So it'll either be manual or it'll be, you know, using lookups or some other way of making that manual process a bit faster, but ultimately it's still a form of manual process. Mm-Hmm. \<affirmative\>. So yeah, it's not, um, 

**Speaker 0 (461:42:45 \- 461:48:35):** Right. 

**Speaker 1 (462:02:35 \- 462:31:15):** Industry is not as advanced as you'd like it to be. 

**Speaker 0 (462:47:35 \- 472:01:55):** Thanks. Yeah, that's very interesting. And, uh, now can you, would you like to tell me your wishlist, for example, uh, from AI that to what are the low hanging fruits in your research journey, either in qualitative or quantitative? I mean, you, we have covered basically a bit of everything. Mm-Hmm. \<affirmative\>. But if you have to gimme like a couple of, uh, low hanging fruits that this is what you want to see, uh, happening and that can increase the productivity, not replacing human, but uh, empowering the human factor. Yeah. So what, what, what, what would be those ideas or list? 

**Speaker 1 (472:11:45 \- 498:16:45):** Yeah, I just gave you the first one. I think low hanging, lowest hanging fruit would be how can, um, incomplete data become more complete quicker so that the point of insight creation can be earlier in the process and you save that time. Basically. If we can turn around content insights faster, I think that would be relevant. Um, and also that, you know, that would just make it a more time efficient process. I think that one other interesting area is, um, we, our content is consumed in every country in the world, but every country in the world is culturally very different to each other. Some of them are much close other, and that's a big challenge, which is if we can get to a consistent way of assessing across markets around, but within the context of the culture of that country. Like that's, you know, there's a lot of work that basically has to be done at a country level, at a local level, 'cause of the nuances in that market. I imagine if there could be a, um, AI tool that allows us to create more of a level playing field where mm-Hmm, \<affirmative\>, you know, we can model out how something might look across multiple markets, but taking into account all the factors that exist in that market like that doesn't feel like that exists. Um, and the other one is 

**Speaker 1 (498:49:35 \- 509:46:35):** Age old problem about, um, box office and theatrical windows. Um, so the way that the whole of the movie industry works is from hitting the cinema through a number of different windows and, um, the windows where consumers can opt in to buy that content or watch that content or rent that content or, you know, get a DVD of that content. And, um, I don't think that the film industry has, you know, I think there's more to, to more to learn for the film industry there, basically overall, 

**Speaker 0 (509:56:05 \- 510:01:55):** Right. 

**Speaker 1 (510:12:55 \- 511:27:15):** To make that a cleaner process and to maybe to model out in a more advanced way. 

**Speaker 0 (511:35:35 \- 514:26:35):** Mm-Hmm. \<affirmative\>. Alright. Thank you very much, Patrick. It was really interesting, uh, chatting with you. I learned a lot. Uh, do you have any questions for me? 

**Speaker 1 (514:43:55 \- 514:59:35):** No, I don't think so. 

**Speaker 0 (515:16:05 \- 516:38:55):** Okay, great. Uh, thanks again and, uh, have a nice rest of the day. Cool. 

**Speaker 1 (516:41:55 \- 517:12:55):** No, sorry, I did have one question, \<laugh\>, 

**Speaker 0 (517:15:05 \- 517:20:55):** Sorry. 

**Speaker 1 (517:23:05 \- 519:26:55):** Which is, do I, um, do I get sent the Amazon voucher on, um, LinkedIn or do you send it to my email or what? 

**Speaker 0 (519:36:55 \- 521:07:15):** Uh, I, I, i, I, I will follow up about that soon, uh, today. Yeah. Okay. 

**Speaker 1 (521:07:15 \- 521:18:35):** Appreciate that. 

**Speaker 0 (521:28:05 \- 521:54:35):** Thank you very much. A.
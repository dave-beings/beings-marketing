  
**Speaker 0 (10:45 \- 10:25:15):** Hello? Hi, Sarah. Can you hear me well? Yes. Thank you very much. Thanks a lot for connecting, and thank you very much for your time. I'm, uh, uh, \<inaudible\>. I'm a product manager in the research and insights at, uh, uh, beings.com. It's a, uh, it's a newly, uh, set up startup company. Uh, we are developing AI products for, uh, market research and to improve customer experience. Uh, we have another participant here called ada. It's our, uh, note taker developed by our company. Uh, do you mind if it keep recording the meeting or you have any problem? No, 

**Speaker 1 (10:25:35 \- 10:35:15):** No problem. 

**Speaker 0 (10:50:25 \- 13:50:35):** Okay. Thank you very much. Uh, so, uh, can we start bit a little bit about you explaining about your job? What are your day to day responsibilities? 

**Speaker 1 (14:17:55 \- 29:47:15):** Okay, for sure. Um, I apologize in advance. So I've contracted covid, so I'm not at my absolute best today, \<laugh\>, but, um, how do I go \<laugh\>? Um, so, um, I work in, uh, pharmaceutical market research, so that comes with its own special challenges. Our audience is slightly different, it's slightly more sensitive. Um, we don't use all of the same sorts of techniques as our consumer market research colleagues do. Mm-Hmm, \<affirmative\>. Um, and quite often we find that, um, tools that are designed in a consumer setting don't always fit the nature of our business. So that's kind of where we come from. I've been doing this for about, um, 25 years. Always qualitative, always pharma, um, always international. So I only deal with prescription products, lots of oncology, lots of rare disease. 

**Speaker 0 (30:31:55 \- 35:41:25):** Very interesting. Thanks a lot. And, and like, given that your background is also from behavioral science, can you gimme like some example that, uh, how did you successfully, uh, integrated, uh, your experience from behavioral science into qualitative research at your current job? 

**Speaker 1 (35:59:04 \- 54:19:25):** Sure. Um, so I've been specializing in behavioral science throughout the last eight years now. And actually I consult, rather than doing too much live research, I consult on other people's projects now, and I do that qualitatively and quantitatively. And our behavioral science falls into two camps. So first of all, it's using behavioral science and behavior change theory to help our clients do better things with their products more strategically, but probably more relevant for what you are asking is using our understanding of, um, why people do what they do, what biases are present to help us ask better questions. So I do a lot about, um, helping us try and make our respondent experience a bit better, try and make our, you know, reduce our attrition rate. So try and make things quicker, faster, more visual, less complicated, easy for people to do, and try and ask questions that, um, help people to tell the truth a bit better. Because, you know, if you said to somebody, tell me everything you've prescribed over the last six months, you know, you're not gonna get a very accurate answer. So trying to make it a bit more bite-size and anchored in actual behavior rather than just kind of, you know, trying to get 'em to remember things. 

**Speaker 0 (54:36:35 \- 62:01:55):** Yeah, right. Thanks. And, uh, you, you mentioned something that, uh, the traditional tools available for market search are not always very useful for your specific industry. So since you're like expert in this, uh, life sciences industry, so what are the unique challenges or, or the opportunity you would see, uh, that you're, that that someone can face if they want, use AI in quality to research in your specific sector? 

**Speaker 1 (62:23:15 \- 74:14:35):** I think there's a, a few things actually. So the first thing is, uh, lexicon. So our language is very specific. It contains a lot of very specific drug terms, body part terms, medical terms. And if a language model isn't built for pharma, it's, it takes a lot of training to get it up to speed. So when we first dabbled in speech to PS, for example, it really wasn't very good and we've had to spend a lot of time we working with partners to kind of give their models enough information to get 'em used to that language. Um, the second thing is, um, GDPR. So with, uh, anything sensitive obviously has much higher levels of GDPR. And then the third thing, I dunno if you've come across adverse event reporting. 

**Speaker 0 (74:27:35 \- 74:49:45):** Yeah, I heard the name. Yes. 

**Speaker 1 (74:56:55 \- 82:25:05):** Yeah. So anything that, any adverse event of any product, whether that is a dosing thing or a side effect, or it has to be reported within one business day of it, we, we, and the rules are different slightly, sometimes it's from when I as a researcher read the data. Yeah. But sometimes it's from when the patient or doctor says it. So if you're doing an online community, for example, someone's gotta be monitoring it really regularly to make sure that you don't miss it because then you miss your window of reporting. 

**Speaker 0 (83:09:35 \- 88:03:25):** Sorry. So Yeah. Okay. If, if I understood correctly, so you're saying that the, the kind of data or the quality of data is evolving so quickly that if those tools are not being updated regularly than the automated possessions or the AI driven possessions may not be useful for you? 

**Speaker 1 (88:22:45 \- 102:19:25):** I think it's the other way around, actually. I think they're getting better. I think most, most of the suppliers that we were talking to to start with had developed their models based on consumer panels. So they just didn't have that understanding. So they would translate drug names as random English words, you know, um, but they are getting better. So I think over time that's improving and it will become a bit more fit for purpose. Um, so as otherwise, I think most things, I'm trying to think what we use. So things like speech to text, they, they have to be trained on health things like, um, virtual eye tracking we use, and I think that probably applies like humans are humans wherever you are. But there is some debate at the moment about whether it still applies in China and Japan and Korea, for example, if your some, if your panel is developed based on people in, in the UK and America, those sorts of things. 

**Speaker 1 (102:35:05 \- 114:44:05):** Um, there was something else I thought of then. I forgot what it was. Oh, yeah. Simulated data. I'm not had much experience with simulated panels. Um, I just haven't, people are talking about it. I get what it is, but I have not embraced that yet. But I do wonder when we come to that phase, you know, they're not simulated panels of doctors. I suspect they're gonna be simulated panels of people that buy products or, you know, it would, it would have to be built with doctor 'cause they talk differently. They're much less emotionally connected to brands, for example, those sorts of tools that, you know, they're, they're trained not to be as emotional. That doesn't mean that it, they're not emotional. They absolutely are, but it's harder to find, they're not as connected to brands as you would be to, you know, if you were purchasing something. 

**Speaker 0 (115:05:15 \- 127:42:15):** Yeah, right. That's very interesting. My, my, my background is actually from data science, computational modeling and simulations. Okay. So, um, yeah, I'm, I'm very in, I'm coming from particle physics background, but for the last 14 years I've used data science and all these data analysis techniques. I'm very interested, uh, to understand a bit more about the simulation. When you talk about simulated data, are you like, uh, trying to see that when people use examples of user personas, like a different kind of example that this is a user story. So you want to basically to give that you want to create a simulation, so how it'll interact within a certain environment or can, can, can, can you tell me a little bit more about, uh, what do you call simulated data? I'm 

**Speaker 1 (127:42:15 \- 145:17:34):** Very interested. I can try. I, I'm, I think my background is sort of the opposite of yours in the sense that I still have music on cassette and my children need to program the TiVo box for me. But, you know, so I'm a bit of a late adopter. Um, my understanding is when I listen to people talk about it, you know, when you go to conference and they're saying, how is AI gonna change qual research? Um, and the, the people are talking about where we would have a panel of doctors that sit there and we can go to them with any kind of question and they would answer it. Now you can do it without having to have the doctors present. So there there's less fatigue. You don't have to pay them as much. It's quicker. You don't drop out, you get good response rates. The kinds of questions they're asking, I don't know so much my consumer colleagues, I know it in a lot with advertising testing. So you run your visual or your, you know, your messaging past the panel and you can predict that people don't like this color. People tend not to like that word. You know, you can change the phrasing. I assume that's what it is. But that's an assumption on my part. And a ad testing actually is relatively small part of what we do. 

**Speaker 0 (145:46:05 \- 154:01:15):** Yeah, yeah. I'm just concerned here about one tiny thing about introduction of bias in your simulated data because, uh, when, when you're talking to actual cases, they can say anything. The situation could be anything. But when you're creating simulation, those are like a hundred percent controlled by your understanding what you want them to do. So I'm wondering that, uh, uh, how do, do you have any idea how to remove the bias from that simulated data? 

**Speaker 1 (154:16:15 \- 168:42:15):** No, and it's one of the things that stops me embracing it a bit at the moment, to be honest, that it, I worry that it will not, that the answers will not be reflective of the kinds of respondents that I talk to. And I worry that, uh, it will, there will be an element of bias in it for sure. Mm-Hmm. \<affirmative\>. And the same thing with, um, you know, like the large language models, you only get out what you put in, don't you? So, you know, if we're building data built on, um, electronic health records, for example, with prescribing, you know, and there's a bias in prescribing, you're gonna get that bias played right back to you. So we know, for example, that women are undertreated that, you know, people of color are often undertreated, people that have low socio, um, economic groups are undertreated. And then do you get that played back in terms of likely diagnosis? Probably yes. Or treatment choice. So I think it's, um, we talk a lot about everything's ai, we talk a lot about that. Are we actually using it? Probably not so much. 

**Speaker 0 (169:18:05 \- 174:37:35):** Yeah. Let's say that. Not not, yes, \<laugh\> yes, yes. Not, not yet. And, uh, in terms of leveraging AI in qualitative research, can you describe some of the recent example where, where, where you have actually started to use it and uh, you were not that scared and you you actually liked it, where you found it useful? 

**Speaker 1 (175:03:45 \- 194:23:35):** I really like the, the speech to text function, and I'm very interested in the future where that might go. So we've, we did work with one supplier that offered thematic analysis. So you, you put your one hour transcript in and then it transcribes it for you, which was good. And then it tells you what the main themes are and you can question it. So what do doctors think are the biggest barrier to prescribing, for example, that bit I absolutely hated because it was just factually wrong. So I'm sure the tech will get there, but it wasn't there yet. Um, but I'm really interested in something that can take my transcripts and say these doctors, they speak differently to those doctors. They use different words and the language that they're using is not reflective of the language that patients are using. And it's not reflective of the language that you are advertising to them in, you know, there's, there's a disconnect and if you fix that disconnect, then you can help doctors and patients communicate better. You know, you can give patients better information, improve their wellbeing, improve their outcomes. I've yet to make that work yet, but I feel like that's in the very, in the quite soon future as opposed to, you know, the more distant future for some of the other things. 

**Speaker 0 (194:53:05 \- 199:55:25):** Right. Yeah. Thanks. So, so just to understand a bit more. So, so, so you're saying that the current tools are not giving you the right masses from the same transcript? Uh, they don't understand the context very well, you mean? So yeah, it more 

**Speaker 1 (200:05:15 \- 212:17:55):** Example, um, the, we asked about, uh, I can't remember exactly what drivers and barriers to prescribing a heart drug, for example. Uh, and we talked about what the drivers and barriers were, and I'm interested in what comes up spontaneously. And then after about 45 minutes of interviewing, we said, well, what if this happened? Would that be a problem? And the doctors all went, oh yeah, that would be a problem. So when I asked the ai what's the biggest barrier, they said that thing that I'd prompted on at the end, but nobody had thought of it spontaneously. It's not a current barrier, like is probably unlikely happen, but because they'd all said, yeah, that'd be a big barrier, that's the bit it picked up and it didn't seem able to kind of take into context the fact that all the spontaneous stuff, a whole 45 minutes out of an hour long interview to talk about that at all. 

**Speaker 0 (212:41:05 \- 216:20:55):** Yeah. So, so yeah, picking up on words could be powerful but also could derail the whole discussion if we, if you is like really just picking up words and not understanding the overall context and Yeah. Did they understand? 

**Speaker 1 (216:52:45 \- 226:49:55):** Yeah. Yeah. And I didn't talk about chatbots either. I dunno if that's interesting, but like mod chatbot moderators. So I hear a lot about, um, scaling up qual, you know, qual at scale. And to me that's not qual, it's something else. It's not quant and it's not qual either. It's somewhere in the middle. And I think there's a place for that. But I dunno, as, as a health researcher, we spend years being trained on helping people feel comfortable, allowing them to talk about topics that are sensitive. And I do get that maybe that level of removal can be quite good. You know, maybe some people prefer to talk to a chat bot. 

**Speaker 0 (226:55:35 \- 227:09:15):** Mm-Hmm. \<affirmative\>. But 

**Speaker 1 (227:24:25 \- 232:39:05):** A lot of time they don't. And the difference between, you know, if somebody says, do you take your medication? And you go, oh yeah, I always take my medication. And what they mean is I always take it, but it's four hours late or you know, oh, I'm better say that I take it because you know, I'm gonna be in trouble. If not, or you know, I do take it this week, but I didn't take it last week. Like, the chat bot's not gonna pick up those things. 

**Speaker 0 (233:11:35 \- 240:37:45):** Yeah. They will just pick up the word and, uh, yeah, they, they will everything. And what, what do you think if it's happening like a live video interview and if chat bots or other automation or AI tools are also like scanning the facial expression or sentiment analysis and trying to figure out if person is kind of holding up the information or you think it's too much at the ethical, uh, conflict border that uh, we shouldn't even think about that. 

**Speaker 1 (241:01:25 \- 247:11:25):** I dunno. I mean, I know that our company has been using it for, um, tracking responses to, uh, moving ads, like video ads, like TV ads. Mm-Hmm. \<affirmative\>, um, in health we don't use that simply because they don't do TV ads for doctors very often. That's what I was gonna mention. Um, so, um, sorry, my husband's on another call. Um, no 

**Speaker 0 (247:11:25 \- 247:14:05):** Worries. 

**Speaker 1 (247:23:45 \- 248:10:05):** Um, if it's loud, let know, 'cause I can move to the kitchen. No, 

**Speaker 0 (248:11:45 \- 248:28:05):** No, that's totally fine. 

**Speaker 1 (248:41:05 \- 254:59:35):** Um, so I, I don't have an issue with doing that. I dunno how reliable it is. It just doesn't really apply to my business because I, I think, I think there's so many reasons why, particularly if you know, you're talking to a chat bot, that I would be less respectful if I was talking to a chat bot than talking to you. You know, I might check my phone or, and there's lots of reasons why my facial expression might change. 

**Speaker 0 (255:33:45 \- 263:24:45):** Oh yeah. That's very interesting. Yeah. Yes, indeed. And, uh, so like o over the last many years you have, uh, uh, moved from one management role to another management role and uh, also in terms of qualitative research, you had very different roles. So, uh, how, how has your approach to the, uh, qualitative research world, uh, over the years and uh, especially in the light of, uh, these emerging technologies like AI these days? 

**Speaker 1 (264:01:25 \- 276:04:05):** I think it's difficult because I think that it's very tempting this, like I said, this whole idea of quality scale. It's quick and fast and cheap and there's a bunch of open-ended questions. It's very tempting for our clients. I think it is quite different to what we sell, which is much more expensive and slower and bespoke and sensitive. And I maybe there's a place for both. I, I'm, like I said, I'm late to adopt quite often, but I think the world is changing and if we don't adapt, you know, is going that way, there isn't a choice. So we need to adapt better. And maybe there are some things that need a very sensitive in-person approach and maybe there are a lot of things that don't, especially as the world gets more used to talking to chatbots now, it becomes more commonplace. We're used to it all the time. 

**Speaker 1 (276:13:45 \- 284:39:45):** We did try a while ago doing, um, uh, interviews through, um, smart speakers and it was absolutely awful. I mean, if you've ever, I've tried to get mine to ask me when, when it's gonna rain and like four hours later she's still going, I'm sorry. I dunno the answer to that. You know, every time someone stops speaking it close the question and asked a different one. But the tech will improve and the large language models will get trained on health. So I think it will go that way. But I think there, I'd like to think there will always still be a place for a human connection for the rapport that you build. 

**Speaker 0 (284:56:05 \- 292:04:15):** Sure, sure, sure. And like, like previously you said that when you're talking to chat bot, you would be less respectful and with the rise of ai, if they're like a more automated tools available in the marketing, people are interacting more with those chatbots or a or AI tools, do you think that the human psyche will go by default towards becoming more rude and that could, uh, impact society and could you consider like drama \<laugh\>? 

**Speaker 1 (292:35:35 \- 299:22:05):** I dunno, I, there is something about being a keyboard warrior, you know, having that level of being removed from like, you just don't care. Um, gosh, I hope not. That's a very depressing thought, isn't it? I think that the, the chat bots of the AI moderators are really good for finding out facts quickly. Particularly if they can, they can make the experience as a respondent more fun, simple visual. They're less good I think at finding out the deeper and why, why, 

**Speaker 0 (299:40:55 \- 307:48:45):** Right? Yes. Yes, indeed. And, uh, so like you have also worked in a market research, but in like different sectors. So how would you like to tell a little bit more about the common, uh, inefficiencies that you have observed in traditional qualitative research per processes in, in various sectors? And uh, how do you think AI could address them? Uh, some, some low hanging fruits. 

**Speaker 1 (308:03:45 \- 320:53:25):** Um, I've only really worked in pharma, so I've only got the one sort of benchmark talk from, I hear my consumer colleagues talking about having AI to write discussion guides for you, that doesn't work. It works sometimes for me. So for example, ad testings, if you're testing an ad, the questions are gonna be quite formulaic. AI could definitely help me with that, make sure I haven't missed anything. Write a first draft for me. But if I want to find out about what's your experience of living with lung cancer, I wanna write that myself. So I think it is a good, it's a bit like having a junior researcher. I think it's a bit like someone to do your first draft. Mm-Hmm. \<affirmative\>, where I found it particularly successful is just helping me get away from that white page. You know, when you're looking at a blank sheet and you're like, I know what I wanna say. 

**Speaker 1 (320:55:25 \- 337:23:15):** I just dunno where to start. Sometimes it can be very helpful to just give you a, some ideas to get going. Then you hate all of them, but now because you hate all of those, you know where you want to go next. So things like, um, um, I say I don't use it actually for writing background sections for proposals because again, health is so specific. Um, but I can see that it could do that in terms of 'cause human discussion guides. I think it could take some of the work out that the big thing for me is analysis. Content analysis used to take hours and hours and hours and now I can get speech to text, I can get it done instantly and I still gotta check the transcript 'cause it's not brilliant, but I can check it in an hour rather than, it used to take me about four or five hours to transcribe an hour and a half interview. So that's really good. And I think if it can help me spot patterns in that data or spotlight like patterns in language that I would've had to done manually, then that would've taken days. You know, at least I can look at it and go, yeah, I don't think that was interesting, but this one might be. 

**Speaker 0 (337:46:05 \- 352:10:05):** And yeah, that's, that. That's very interesting. Uh, but here we are talking about only this piece to text, uh, when, when you have the transcription from, uh, interviews and what, what, what do you think, is there anything else where AI can also help in your overall data analysis? And not just data analysis, but also data visualization or at the end, like a presentation or helping you to, uh, summarize your data in a way so that you can talk to different audience. Like when you're talking to management board, you would, you, you're not probably discussing every tiny technical detail, but when you're talking to your team, maybe you are interested in different kind of setups. So do you see, uh, the opportunity of AI to help you there or have you already encountered something like that? 

**Speaker 1 (352:37:25 \- 362:49:05):** I have not actually. That's not something that, um, that I have considered. I think our, my quantitative colleagues that are looking at more numerical presentations, I know they do a lot of data visualization stuff that's automated. I, I don't have experience of that. The qual work that we do is very individual, so it's very difficult to make it, um, to automate it in any way. Um, I, I can see the potential for that. I can imagine asking something to help me reframe something in a language that is easier to understand or more formal. I'd never thought about it though before now. 

**Speaker 0 (363:00:15 \- 374:40:05):** Mm-Hmm, \<affirmative\>. Okay, great. And, uh, let's say when you're preparing your product, like qualitative research product, your product planning, then you're finding participant and then you're collecting data, uh, how often do you collaborate a lot with people to make these decision? Or, or, or you have like a, um, you mostly decide these things by yourself because if you're collaborating, then you also spend a lot of time to get back those decisions and to communicate. So how do you manage this whole research journey from project planning to, uh, data collection and, uh, data analysis and at the end sharing the results? 

**Speaker 1 (375:11:15 \- 383:01:35):** Um, well the up the bit, once I decide I wanna talk to 10 oncologists in Italy, for example, that I then will, that part is outsourced to specialist recruiters. So they, they hold panels of doctors who are willing to participate in research. They set up the appointments, their Italian moderator will go and do the interviews, um, and then they will feed back the audio. So the, there's no, I don't do anything in between saying, I write the questions, send them off, and then they come back with the audio. 

**Speaker 0 (383:24:15 \- 386:25:45):** Okay. So the, so, so the agencies will take care of, uh, how the product is continuing and what kind of information they're collecting and they'll hand it over to you, uh, just audio and you can analyze it in any way you want? 

**Speaker 1 (386:35:25 \- 386:45:05):** Yes, exactly. 

**Speaker 0 (387:30:25 \- 391:28:25):** Hmm. Okay. Great. And so what, what, what would be your advice to the research team or organization that just started to explore the use of AI in the, in in your specific sector? 

**Speaker 1 (391:52:05 \- 394:22:25):** Um, I guess it depends what you mean by ai, doesn't it? So whether you, whether you're thinking what kind of AI you're thinking of, it feels like it's so many different things. 

**Speaker 0 (394:36:45 \- 405:21:55):** No, I mean, uh, I, I understand the, the, the overuse of AI these days because in in market many people are just using simple automation is sold as ai Yes. Simple s which are not really intelligent. That is just, uh, some \<inaudible\> statements running in the background that if somebody's asking this question, give them this answer yes. That that is not ai. I'm talking about somewhere, uh, for example, like, uh, you know, when, uh, there is a transcription available and then it can provide you automated summaries or something that can actually help you, something that has a hint of intelligence and not just automation. 

**Speaker 1 (405:36:15 \- 414:06:35):** I would love that I wait for the day that that happens. That takes some of that. My worry with it is that at the moment I don't trust it. And I worry that people, people humans naturally are quite lazy. You know, if you, if it looks like a duck and it quacks like a duck, they're not gonna go and check it is actually a duck. So are they gonna pick up the hallucinations? And if they have to spend so much time looking for hallucinations in data, is there any benefit in having it start with? So I guess it'll come eventually it'll come, but I don't wanna be the person that's testing it out in the middle 

**Speaker 0 (414:38:55 \- 422:19:35):** \<laugh\>. Uh, okay. And can, can you tell me a bit more about these, uh, I understand there's, uh, a resistance to go towards, uh, or reluctance to go towards a new tool of the market, but, uh, can you tell me a bit more about these biggest barriers or, or the challenges that, uh, people can face in adopting AI in qualitative research in your field? Or, or in general, and how can we overcome that? Overcome? So, 

**Speaker 1 (422:25:15 \- 441:22:35):** Um, let me see, the biggest challenges I there, I think there are some technical challenges. So do, for our company, for example, we can't work with any competitors. So if we don't have a product ourselves, we can't use anybody else's. So there's a technical challenge from that point of view. There's a, there's a, a general sense of mistrust. And I think because we don't understand quite how everything works, we are on the side of caution. So things, all the questions that I probably wouldn't ask that my colleagues ask, like, you know, how's your data stored? Where in what country? Where's your GDPR? You know, where'd you hold your data center are, what you gonna do with my data? How do I know? Is it gonna be out there? Is it training chat GPT open ai or are you gonna have a closed system? And if it's a closed system, how are you gonna train it well enough so it understands if you've gotta trade it from scratch, you know, it has to be trained on something. So yeah, is it ready? Um, and then there's the whole thing about do we trust it to be true? 

**Speaker 0 (442:19:05 \- 444:20:35):** Yeah, yeah. So yeah, data privacy is like your biggest concern. Your, your biggest concern is data privacy. 

**Speaker 1 (444:26:15 \- 448:32:45):** My com not for me personally. Maybe not so much, much. I, I, I'm a bit oblivious to it. I just assume it's gonna work. And if you tell me it's private, then I'll just go, okay, it's private. But for my, my company is, uh, was very, very cautious and risk averse with regard to data security. Yeah, 

**Speaker 0 (449:03:15 \- 461:30:05):** Right. Thanks. And let, let, let's say in, in ideal conditions that data security is solved and people are trusting it. Yeah. And uh, also from technical point of view, let's say whatever you wish for is, is granted. It's there, all the technical advancements are there. So in that ideal scenario, what, what would be your wishlist that you would like to see from, uh, ai? How, how it can really, uh, make, uh, the, uh, the day-to-day job of a qualitative researcher or an organization, uh, where many people are working together. Uh, how can it, uh, what, what, what, what are your reason for that kind of, uh, AI application that, how it can really help you better? Just, just some points. 

**Speaker 1 (461:45:55 \- 477:17:45):** Okay. So generally, um, I would love it if it could take my 30 transcripts and tell me the themes accurately and maybe find some themes that I haven't spotted. Like I know it's gonna be product efficacy and safety. I know that's coming up, but maybe there's some themes amongst these people that I didn't notice. So I'd love it if you do that, find some subtle themes. Um, I thought something else and then I forgot it. Hang on a minute. It'll come back to me. Oh, yes, I would love it. This is a slightly different topic, you know, internal filing, like everybody did a proposal on that about five years ago. Has anyone got that proposal? No, no one's got that proposal. You know, that sort of knowledge retrieval internally, um, that, yeah, that was amazing. So, you know, we've, we know we've done six studies on liver cancer, but we can't remember what the main products are or you know, what the issues were in the market at the time. Some way to kind of collate and retrieve that data that isn't manually scrolling through SharePoint files would be amazing. 

**Speaker 0 (478:20:25 \- 492:06:45):** Yeah, that's very interesting. We are actually going into that direction, like when, uh, we, we are developing something, when you will interview people and, uh, uh, you are collecting a lot of words. Uh, you will have a lot of interviews and then, uh, your personalized, uh, research assistant, uh, will be there. It's an AI driven tool, so you can ask it question that, what is the answer of this question based on my data? So it'll go and of go through different kind of, uh, interviews that you have, uh, uh, performed in that particular project space. It can give you answer, it can also compare the quality of answers, uh, given in different interviews. So I'm very happy to hear. Wow, okay. I'm very happy to hear that. Uh, uh, you, you are interested in that. 

**Speaker 1 (492:21:45 \- 496:43:25):** Yes. Yeah, that would be really good because you, you sort of gather all this knowledge and then bits of it drop out of your brain as you go over time, or you can't quite remember what the file was called. So trying to write the prompt is really difficult. So something that was a bit more intelligent that could say, did you mean one of these six things that would be really good. 

**Speaker 0 (496:59:55 \- 502:14:25):** Yeah. So yeah, very efficient data management so that you can quickly get it just like you're doing it with your brain. You think about last year it happened and quickly it's coming. It's not taking time. Yeah. Right. Thank you. Thank you very much. I really enjoyed, uh, talking with you. Do you have any question for, for me? 

**Speaker 1 (502:40:15 \- 504:28:55):** Um, do you think that you will have something in the, in the pharma space, or do you think you'll have something more general over time? 

**Speaker 0 (504:54:25 \- 528:48:45):** Uh, I mean we, we, uh, we want to target, uh, both like healthcare sector and, and FinTech in the beginning, but I really understand your reasons that we need a bit more training for, for pharma sector as well. Uh, because the rules and regulations are a bit stronger because we are dealing with very sensitive health data as you, uh, explain, uh, we will definitely be providing something for healthcare sector as well. Uh, but in next two to three months, we are launching our, um, MVP, uh, first time in the market. So yeah, uh, it's definitely in our plans, if not interesting this year. But then, because the qualitative research is not really a sector specific thing, right? It's a, it's a, in every sector people are doing that. Either it's FinTech, healthcare or, or in any, any other sector. Uh, but, uh, yeah, when it comes to ai, we need to make sure that, uh, it's understanding the context and that field very well, because the same words may have a very different meaning in the, in different sectors. And then if your tool is not understanding that, then the suggestions coming out of that could be very misleading. So instead of empowering humans, we could be really misleading. So, uh, yeah, we, we are very cautious about that concern. Then we will try to remove that, uh, that, that bias as well. But in terms of sectors needs, we, we we're definitely targeting healthcare as well. 

**Speaker 1 (529:12:45 \- 529:30:45):** Interesting. Oh, well, good luck. 

**Speaker 0 (529:54:55 \- 533:03:25):** Thank you very much. Uh, thanks again for, for your time and, and talking to us. Uh, I will, uh, send the Amazon voucher through on, on your emails very soon. Oh, 

**Speaker 1 (533:03:25 \- 533:14:45):** Lovely. Thank you. 

**Speaker 0 (533:25:15 \- 533:50:05):** Okay, great. Thanks. Thank you.
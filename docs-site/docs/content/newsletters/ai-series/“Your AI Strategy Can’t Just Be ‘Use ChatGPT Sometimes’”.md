Meta Description: *Using ChatGPT isn’t a strategy\. This is my take on why AI only works in research if you have real structure behind it and how we built for that\.*

<a id="_yg8vgwx5gv7a"></a>

<a id="_ffap6zdf6dhp"></a>Your AI Strategy Can’t Just Be ‘Use ChatGPT Sometimes’

We’ve all done it\. Typed a question into ChatGPT, got something semi\-useful back, and thought: *“Maybe this is how we do things now?”*

Granted a lot of the time it’s been for food shopping, maybe a fitness regime, or an itinerary for an upcoming city break\. Usually it’s just life admin\. But sometimes, it creeps into actual work\. Your research work\. 

But here’s the truth: AI doesn’t make you a better researcher\. Process does\.

Without one, you're just winging it, and faster\. And faster bad decisions don’t become better ones\.

## <a id="_msdqrwxqtmvh"></a>__What Do You Need to Know__

### <a id="_vqbo2o9pkeb"></a>__The problem?__

ChatGPT is being used instead of structure\.  
People are skipping the hard, foundational parts of research and asking AI to fill the gap\.

### <a id="_wqw1vr4vziw"></a>__Why it matters?__

When there’s no clear process, the output might sound smart but lacks weight\.  
Clients can’t trust it\. Researchers can’t build on it\.

### <a id="_jm157mpu5v58"></a>__Where it breaks?__

- Teams lean on AI before designing the approach  

- Frameworks are ignored in favour of quick answers  

- There’s no system to check what actually matters  


### <a id="_narb9qu3bf4"></a>__What could help?__

Bring AI into your existing process, not in place of one\.  
Use frameworks like Jobs to Be Done to guide interpretation\.  
Let AI support the work, not define it\.

In mid–2024, the Tony Blair Institute for Global Change [released a buzzy report claiming AI could perform up to 40% of public sector jobs\.](https://institute.global/insights/economic-prosperity/the-impact-of-ai-on-the-labour-market)

You may ask, how did they arrive at that number?

__They used GPT‑4 to evaluate a dataset of around 20,000 public‑sector tasks from O\*NET\.__

They plugged the data into ChatGPT\.

As you can imagine, the backlash was swift\. Critics on X accused the Institute of “making \*\*\*\* up\.”[ ](https://www.pcgamer.com/software/ai/ai-predicts-that-ai-job-automation-is-beneficialthis-is-absurdthey-might-as-well-be-shaking-a-magic-8-ball-and-writing-down-the-answers-it-displays-says-expert/)

[AI ethics expert __Prof\. Emily Bender__ likened it to *“shaking a Magic 8 Ball and writing down the answers it displays\.”*](https://www.pcgamer.com/software/ai/ai-predicts-that-ai-job-automation-is-beneficialthis-is-absurdthey-might-as-well-be-shaking-a-magic-8-ball-and-writing-down-the-answers-it-displays-says-expert/) 

Observers also flagged the methodology for asking an AI to assess its own potential and raised questions about conflicts of interest, since the Institute is backed by pro\-tech donors\.

Ultimately, even if the facts themselves were 100% spot on, backed by the best research, without a framework and without a way of effectively “showing their working”, it loses credibility\. 

And that is exactly the kind of bad press that so much of AI in research is getting\. Either it’s “taking jobs”, or flattening research, or in some way ethically “icky”\.  
  


## <a id="_t7mlkc5n2b6p"></a>Shiny Object Syndrome

However, this is very much a case of the early days of shiny object syndrome\. Again, this is something that is innately human\.

Think of a largeish purchase you’ve made\. One you’ve really laboured over\. Something like an expensive coffee machine, perhaps?  
  
That machine’s going to change everything\. No more Starbucks, just beautiful, tear\-inducing flat whites made by your own hand\.

Then three months down the line all you are doing is making a standard Americano in your sleep\. The sheen at the beginning means you can do everything but actually a lot of the time it’s not appropriate\. 

And that’s what we’re seeing in a lot of in research at the moment when it comes to AI\.

People got excited\. Rightly so\! But now it’s time to stop treating it like a miracle and start building it into something useful\.  


## <a id="_klmyqdvqk14a"></a>  
Structured\. Repeatable\. Human\-led\.

This is what AI in research should be because despite what the grabby headlines say, AI isn’t “replacing” good research\. Instead, when used properly it’s just revealing who was relying on instinct and sticky notes all along\. That’s not to say great insights can’t be achieved on these, but a structured framework to get to that outcome is more likely to hit the target regularly than “vibes”\. 

And here’s the thing no one wants to say out loud: Most of the time, when AI “fails,” it’s not the tech that’s the problem\. It’s the absence of a process\.

Without a framework, without even considering the review stage\. It really is just vibes and a ChatGPT window\. 

The cursor blinks\. [The AI flatters you\.](https://openai.com/index/sycophancy-in-gpt-4o/) But is it actually *right*?

### <a id="_j4d3izk53egf"></a>__AI doesn’t flatten research\. People do\.__

When research is reduced to vague headlines, that’s because someone chose speed over substance\. 

AI will give you quick summaries\. It will highlight patterns\. But it doesn’t know which parts of the data are significant\. It doesn’t understand what matters to your audience or your client\. 

That still comes down to process\. __And judgement\.  __

Even if you USE AI, if you don’t have a structure to hold it against, you can end up meandering, chasing shadows and finding side quests and rabbit holes aplenty\. 

This is where frameworks like __Jobs to Be Done__ help\. JTBD gives structure to understanding why people make choices\. It helps you look beyond preferences or demographics and focus on real motivations\.

AI can support this work\. It can help group similar behaviours, map out decision pathways, or spot language patterns in interviews\. But it won’t tell you what someone is really trying to achieve when they buy something or switch to a new service\. That comes from good research design and careful interpretation\.

Teams who already know how to use frameworks like JTBD are getting value from AI\. They’re using it to reduce manual effort, not to make decisions for them\. They know when to challenge the output and when to take a step back and check the context\.

AI is useful\. But only if you're already doing the work properly\.

## <a id="_5iwgsc7jvu2z"></a>Beings Is ALL About Frameworks  


At Beings, we didn’t just build an AI tool for the sake of it, we built it because we live inside research workflows every day\. We saw the messy middle, the time\-drains, the false starts\. And we thought: what if AI actually fit into those processes, instead of overriding them?

We have literally built an AI tool that supports research specifically\.

And we’ve built it with one thing in mind: making research workflows stronger, not sloppier\.

That means creating tools that work with the frameworks researchers already use\. Whether you’re running exploratory qual through Jobs to Be Done, mapping commercial risks, or delivering a mixed\-methods strategy piece, AI should support the work, and not flatten it\.

We’ve designed our tools to help with the parts of research that take time but don’t always need your full brain\. Things like unblocking early analysis, clustering open\-ended responses, or drafting a structure so you can focus on the story, not the formatting\.

But it only works because it’s been built to fit within real research process\. Not as a replacement for rigour, but as a way to support it\.

Because the value of research doesn’t come from speed\. It comes from what you do with it once you’ve slowed down enough to think\.

So no… your AI strategy can’t just be “Use ChatGPT sometimes\.” That’s not a strategy, sorry \(Despite what all the “prompt engineers” are saying\)\!

If you want AI to work in research, you need something real behind it\. Frameworks, designed specifically for purpose, whatever, but just putting lots of data into a mainstream platform and asking it to create something is not going to win your agency prestige\. 

And if you’re wondering what that actually looks like? We’ve written something for that too\.

__Building a Real AI Research Workflow \(Not Just a Hack List\)__


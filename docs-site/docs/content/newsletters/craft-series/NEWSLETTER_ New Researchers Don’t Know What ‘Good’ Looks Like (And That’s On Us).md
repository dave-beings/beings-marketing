*META DESCRIPTION: *__*AI is changing how we work as researchers, but we don’t want to lose the craft\. Here’s why that matters, what’s at risk, and how we should approach it with care\.*__

<a id="_heading=h.a3d0tke2il83"></a>New Researchers Don’t Know What ‘Good’ Looks Like \(And That’s On Us\)

*“If you haven’t had that training\.\.\. how do you know what you’re looking at is actually any good?” \- Parv*

This quote really stuck out to me when chatting with Parv Bhdesha\. There has been so much hype about how AI is going to change everything, not just research, but how we shop, how we eat, how we train, how we *live*\.

  
AI is driving real shift and that’s great\. We are learning new skills, how to prompt, how to analyse and how these things can make life easier\.

  
For anyone over, say, 25, it feels like a bit of a gift\. We’ve got the context\. We can tell when something’s off\. When the AI churns out something that sounds impressive but misses the mark, we’ve usually got enough experience to spot it\. To say, “that’s not quite right\.” We know because we’ve lived it\. Worked it\. Mucked it up a few times and learned the hard way\.

The concern that Parv was having, and one that I echo, and certainly many people across LinkedIn appear to share is what about “the craft”?

—\-

__What Do You Need to Know__

 __The problem?  
__ AI is transforming research workflows\. That’s good\. But as it becomes embedded from day one, newer researchers risk missing the messy, hands\-on parts that teach craft, rigour, and judgement\.

__Why it matters?  
__ Experience builds context\. Without it, we risk relying on tools we don’t fully understand, losing the ability to question or course\-correct when outputs sound polished but miss the point\.

__Where it breaks?__

- AI gets used to skip steps, not support them  

- Researchers trust the output but haven’t read the data  

- Critical thinking becomes reactive, not proactive  

- The basics aren’t taught, just expected  

- Craft becomes harder to pass on  

- Speed is prioritised over sense\-making  


__What could help?__

- Make space for foundational training, not just tooling  

- Use AI to support curiosity, not replace it  

- Choose tools designed for thinking, not just efficiency  

- Keep human oversight central to the process  

- Teach the why, not just the how  


__Want the detail? Keep reading\.__

—\-  
  
Are we teaching AI to do all these things and neglecting to teach the next generation how it was done before? Are we running a risk of losing the basics, being so reliant on AI that we are losing the tricks of the trade, or even the chance to do what we do WITHOUT AI should anything happen?  
  
It sounds so simple, but if you look at how houses were built in the Victorian era, there were flourishes and patterns, things to look beautiful as well as be practical\. Now? How fast can we get this up? Time is money\! Let’s paint it Magnolia and move on\. 

While I’m not saying the craft across industries is no longer there, it’s kind of lacking in the way it used to\. Convenience and profit win a lot of the time over beauty\.

### <a id="_heading=h.nzyaomhs19ia"></a>__Then vs Now: The Researcher’s Learning Curve__

In the early 2000s, becoming a researcher in the UK was a slower, more manual process\. And that was part of the point\. You would usually begin with the basics: ethnography, depth interviews, writing proper discussion guides, learning how to moderate, how to listen without leading\. Transcripts were either typed up or manually coded\. You might spend days clustering Post\-its, reviewing recordings, and watching how more experienced researchers linked ideas that didn’t seem connected at first\.

There was no shortcut\. If you wanted to explain something, you had to understand it properly\.

Now, things look different\. AI tools are built into the workflow from day one\. Interviews are transcribed instantly, themes are auto\-tagged, summaries are generated without anyone needing to read the full transcript\. It saves time and helps speed things along\. But in some cases, researchers are jumping straight to interpreting without spending any real time with the raw data\.

The long hours spent listening, reflecting, and making sense of it all are becoming rare\. The space to sit with something messy and gradually work it through is harder to come by\. And without that experience, it is not always obvious what has been skipped\.

Here is where some of the gaps start to show:

- Critical thinking is harder when everything sounds polished  

- Participants become data points, rather than people with context  

- Biases slip through when you do not know what to look for  

- You miss the subtle cues that tell you what someone really means  

- It becomes harder to push back on shallow insights or ask, “Is that actually true?”  


This is not just about looking back fondly\. It is about making sure new researchers have the foundations to question, to probe, and to trust their judgement\. The basics still matter\. If we lose them, the work changes\. And not for the better\.

This is not about resisting change\. It is about what gets lost when a generation skips the messy middle\. The hands\-on, slightly awkward, sometimes brilliant part where you learn by doing\. If we stop teaching that, we risk becoming too reliant on systems we did not build and do not fully understand\. Skills fade\. Knowledge disappears\. We have seen it happen before in languages, in crafts, in professions that assumed the next wave would just know what to do\.

The basics still matter\. If we lose them, the work changes\. And not for the better\.

## <a id="_heading=h.y16o3561enhu"></a>Are We Losing Craft Already?

And yet, that loss is already creeping in\. A large\-scale study of 816 researchers found that [81% have already integrated large language models into their workflows](https://arxiv.org/abs/2411.05025)\. Most are using them for analysis, summarising, editing, and writing\. The same study found that adoption is especially high among researchers from traditionally underrepresented groups, which suggests that AI is not just changing research, but opening it up\. This is a GOOD thing, but does come with a caveat\.

Another survey from Oxford University Press found that [76% of researchers are using AI tools, but only 8% trust the companies behind them not to misuse their data](https://fdslive.oup.com/www.oup.com/academic/pdf/Researchers-and-AI-survey-findings.pdf)\. So we are using these tools\. Heavily\. But many of us are doing it cautiously\. And in some cases, without the deeper training to know when something is off\.

This is not a warning to stop\. It is a push to get sharper\.

The researchers who will get the most from AI are not the ones using it to skip steps\. They are the ones treating it like a colleague with potential\. Something that can move fast, yes, but that still benefits from guidance, interpretation, and experience\.

When those things come together, the craft and the tools,  the results can be brilliant\. Faster, yes\. But also deeper\. More rigorous\. More democratic\. And better equipped to meet the demands of research today\.

So we do not need to pick a side\. We just need to be clear what we are building, and who we are learning from\.

And if you are looking for tools that support that balance, it matters who builds them\. Beings was designed specifically for researchers\. Not to replace the thinking, but to help you do more of it\. It gives you speed where it helps, and space where it counts\. AI is only as good as the hands it is in\. Beings keeps those hands firmly on the work\.

